{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de datos sobre el Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.preparacion de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "la fuente de datos es un csv sobre el titanic y viene desde la [url](https://raw.githubusercontent.com/datasciencedojo/datasets/refs/heads/master/titanic.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## librerias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic=pd.read_csv(\"https://raw.githubusercontent.com/datasciencedojo/datasets/refs/heads/master/titanic.csv\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## diccionario de variables (features y columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=titanic.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre|Descripción |tipo de dato |clasificación de dato |tratamiento |\n",
    "|---|--- |---- |--- |--- |\n",
    "|``PassengerId``|  identificador único del pasajero. |int | indice| |\n",
    "|``Survived``| si el pasajero sobrevivió al naufragio, codificada como 0 (no) y 1 (si). | int|binary or bool | |\n",
    "|``Pclass``| clase a la que pertenecía el pasajero: 1, 2 o 3. | int| cualitativo ordinal| |\n",
    "|``Name``| nombre del pasajero |str | cualitativo nominal| |\n",
    "|``Sex``| sexo del pasajero. | str|binario | |\n",
    "|``Age``| edad del pasajero. | float| cuantitativo discreto| |\n",
    "|``SibSp``|número de hermanos, hermanas, hermanastros o hermanastras en el barco. | int|cuantitativo discreto | |\n",
    "|``Parch``|número de padres e hijos en el barco.|int | cuantitativo discreto| |\n",
    "|``Ticket``|  identificador del billete. |str |-- | |\n",
    "|``Fare``| precio pagado por el billete. |float | cuantitavo ocntinuo | |\n",
    "|``Cabin``| identificador del camarote asignado al pasajero. |str | ---| | eliminar la cabina\n",
    "|``Embarked``| puerto en el que embarcó el pasajero. | str| cualitativo| |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analisis tecnico "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of      PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10692"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId     0.000000\n",
       "Survived        0.000000\n",
       "Pclass          0.000000\n",
       "Name            0.000000\n",
       "Sex             0.000000\n",
       "Age            19.865320\n",
       "SibSp           0.000000\n",
       "Parch           0.000000\n",
       "Ticket          0.000000\n",
       "Fare            0.000000\n",
       "Cabin          77.104377\n",
       "Embarked        0.224467\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()/len(df)*100 #hay que eliminar la cabina porque quiere decir que el 77% de los datos son perdidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## valores unicos de una serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cantidad de unicos en la  variablePassengerId son 891\n",
      "cantidad de unicos en la  variableSurvived son 2\n",
      "cantidad de unicos en la  variablePclass son 3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df:\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcantidad de unicos en la  variable\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m son \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "for col in df:\n",
    "    print(f\"cantidad de unicos en la  variable{col} son {len((df[col].unique())/(len(df))*100)}\") #esto es para ver la q de unicos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analisis de frecuencias absolutas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived\n",
      "0    0.616162\n",
      "1    0.383838\n",
      "Name: proportion, dtype: float64\n",
      "Pclass\n",
      "3    0.551066\n",
      "1    0.242424\n",
      "2    0.206510\n",
      "Name: proportion, dtype: float64\n",
      "-----------\n",
      "Survived\n",
      "0    0.616162\n",
      "1    0.383838\n",
      "Name: proportion, dtype: float64\n",
      "Pclass\n",
      "3    0.551066\n",
      "1    0.242424\n",
      "2    0.206510\n",
      "Name: proportion, dtype: float64\n",
      "-----------\n",
      "Survived\n",
      "0    0.616162\n",
      "1    0.383838\n",
      "Name: proportion, dtype: float64\n",
      "Pclass\n",
      "3    0.551066\n",
      "1    0.242424\n",
      "2    0.206510\n",
      "Name: proportion, dtype: float64\n",
      "-----------\n",
      "Survived\n",
      "0    0.616162\n",
      "1    0.383838\n",
      "Name: proportion, dtype: float64\n",
      "Pclass\n",
      "3    0.551066\n",
      "1    0.242424\n",
      "2    0.206510\n",
      "Name: proportion, dtype: float64\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "for col in ['Survived', 'Pclass','Sex','Embarked']:\n",
    "    print(df['Survived'].value_counts(normalize=True))\n",
    "    print(df['Pclass'].value_counts(normalize=True))\n",
    "   \n",
    "    print('-----------') #el normalize hace que se quede en porcentaje si se tiene que hacer varias veces esto se debe hacer un bucle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se transforma los datos que no estan bien los valores, por ejemplo edad que estan en flotantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    714.000000\n",
       "mean      29.699118\n",
       "std       14.526497\n",
       "min        0.420000\n",
       "25%       20.125000\n",
       "50%       28.000000\n",
       "75%       38.000000\n",
       "max       80.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'].describe() #el 0,42 es un dato raro que hay que solucionar, ademas el cuartil 25 no cuadra "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Caldwell, Master. Alden Gates</td>\n",
       "      <td>male</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>248738</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>470</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Baclini, Miss. Helene Barbara</td>\n",
       "      <td>female</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2666</td>\n",
       "      <td>19.2583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>645</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Baclini, Miss. Eugenie</td>\n",
       "      <td>female</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2666</td>\n",
       "      <td>19.2583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>756</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hamalainen, Master. Viljo</td>\n",
       "      <td>male</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>250649</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>804</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Thomas, Master. Assad Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2625</td>\n",
       "      <td>8.5167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>832</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Richards, Master. George Sibley</td>\n",
       "      <td>male</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29106</td>\n",
       "      <td>18.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                             Name     Sex  \\\n",
       "78            79         1       2    Caldwell, Master. Alden Gates    male   \n",
       "305          306         1       1   Allison, Master. Hudson Trevor    male   \n",
       "469          470         1       3    Baclini, Miss. Helene Barbara  female   \n",
       "644          645         1       3           Baclini, Miss. Eugenie  female   \n",
       "755          756         1       2        Hamalainen, Master. Viljo    male   \n",
       "803          804         1       3  Thomas, Master. Assad Alexander    male   \n",
       "831          832         1       2  Richards, Master. George Sibley    male   \n",
       "\n",
       "      Age  SibSp  Parch  Ticket      Fare    Cabin Embarked  \n",
       "78   0.83      0      2  248738   29.0000      NaN        S  \n",
       "305  0.92      1      2  113781  151.5500  C22 C26        S  \n",
       "469  0.75      2      1    2666   19.2583      NaN        C  \n",
       "644  0.75      2      1    2666   19.2583      NaN        C  \n",
       "755  0.67      1      1  250649   14.5000      NaN        S  \n",
       "803  0.42      0      1    2625    8.5167      NaN        C  \n",
       "831  0.83      1      1   29106   18.7500      NaN        S  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Age']<1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age']=df['Age'].apply(lambda row:1 if row<1 else row) #esto es para cambiar los valores que hay por debajo de 1\n",
    "#con np.where se puede utilizar pero hay que hacerlo uno a uno "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78     0.0\n",
       "164    0.0\n",
       "172    0.0\n",
       "183    0.0\n",
       "305    0.0\n",
       "381    0.0\n",
       "386    0.0\n",
       "469    0.0\n",
       "644    0.0\n",
       "755    0.0\n",
       "788    0.0\n",
       "803    0.0\n",
       "827    0.0\n",
       "831    0.0\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Age']==1]['Age'].replace(1,0) #esto es otra de forma de hacerlo pero el lambda es mejor, funciona mas cuando quieres reemplazar uno solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para comporbar si lo hemos hecho bien podemos mirar el minimo y a ver que nos sale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22. , 38. , 26. , 35. , 35. ,  nan, 54. ,  2. , 27. , 14. ,  4. ,\n",
       "       58. , 20. , 39. , 14. , 55. ,  2. ,  nan, 31. ,  nan, 35. , 34. ,\n",
       "       15. , 28. ,  8. , 38. ,  nan, 19. ,  nan,  nan, 40. ,  nan,  nan,\n",
       "       66. , 28. , 42. ,  nan, 21. , 18. , 14. , 40. , 27. ,  nan,  3. ,\n",
       "       19. ,  nan,  nan,  nan,  nan, 18. ,  7. , 21. , 49. , 29. , 65. ,\n",
       "        nan, 21. , 28.5,  5. , 11. , 22. , 38. , 45. ,  4. ,  nan,  nan,\n",
       "       29. , 19. , 17. , 26. , 32. , 16. , 21. , 26. , 32. , 25. ,  nan,\n",
       "        nan,  1. , 30. , 22. , 29. ,  nan, 28. , 17. , 33. , 16. ,  nan,\n",
       "       23. , 24. , 29. , 20. , 46. , 26. , 59. ,  nan, 71. , 23. , 34. ,\n",
       "       34. , 28. ,  nan, 21. , 33. , 37. , 28. , 21. ,  nan, 38. ,  nan,\n",
       "       47. , 14.5, 22. , 20. , 17. , 21. , 70.5, 29. , 24. ,  2. , 21. ,\n",
       "        nan, 32.5, 32.5, 54. , 12. ,  nan, 24. ,  nan, 45. , 33. , 20. ,\n",
       "       47. , 29. , 25. , 23. , 19. , 37. , 16. , 24. ,  nan, 22. , 24. ,\n",
       "       19. , 18. , 19. , 27. ,  9. , 36.5, 42. , 51. , 22. , 55.5, 40.5,\n",
       "        nan, 51. , 16. , 30. ,  nan,  nan, 44. , 40. , 26. , 17. ,  1. ,\n",
       "        9. ,  nan, 45. ,  nan, 28. , 61. ,  4. ,  1. , 21. , 56. , 18. ,\n",
       "        nan, 50. , 30. , 36. ,  nan,  nan,  9. ,  1. ,  4. ,  nan,  nan,\n",
       "       45. , 40. , 36. , 32. , 19. , 19. ,  3. , 44. , 58. ,  nan, 42. ,\n",
       "        nan, 24. , 28. ,  nan, 34. , 45.5, 18. ,  2. , 32. , 26. , 16. ,\n",
       "       40. , 24. , 35. , 22. , 30. ,  nan, 31. , 27. , 42. , 32. , 30. ,\n",
       "       16. , 27. , 51. ,  nan, 38. , 22. , 19. , 20.5, 18. ,  nan, 35. ,\n",
       "       29. , 59. ,  5. , 24. ,  nan, 44. ,  8. , 19. , 33. ,  nan,  nan,\n",
       "       29. , 22. , 30. , 44. , 25. , 24. , 37. , 54. ,  nan, 29. , 62. ,\n",
       "       30. , 41. , 29. ,  nan, 30. , 35. , 50. ,  nan,  3. , 52. , 40. ,\n",
       "        nan, 36. , 16. , 25. , 58. , 35. ,  nan, 25. , 41. , 37. ,  nan,\n",
       "       63. , 45. ,  nan,  7. , 35. , 65. , 28. , 16. , 19. ,  nan, 33. ,\n",
       "       30. , 22. , 42. , 22. , 26. , 19. , 36. , 24. , 24. ,  nan, 23.5,\n",
       "        2. ,  nan, 50. ,  nan,  nan, 19. ,  nan,  nan,  1. ,  nan, 17. ,\n",
       "       30. , 30. , 24. , 18. , 26. , 28. , 43. , 26. , 24. , 54. , 31. ,\n",
       "       40. , 22. , 27. , 30. , 22. ,  nan, 36. , 61. , 36. , 31. , 16. ,\n",
       "        nan, 45.5, 38. , 16. ,  nan,  nan, 29. , 41. , 45. , 45. ,  2. ,\n",
       "       24. , 28. , 25. , 36. , 24. , 40. ,  nan,  3. , 42. , 23. ,  nan,\n",
       "       15. , 25. ,  nan, 28. , 22. , 38. ,  nan,  nan, 40. , 29. , 45. ,\n",
       "       35. ,  nan, 30. , 60. ,  nan,  nan, 24. , 25. , 18. , 19. , 22. ,\n",
       "        3. ,  nan, 22. , 27. , 20. , 19. , 42. ,  1. , 32. , 35. ,  nan,\n",
       "       18. ,  1. , 36. ,  nan, 17. , 36. , 21. , 28. , 23. , 24. , 22. ,\n",
       "       31. , 46. , 23. , 28. , 39. , 26. , 21. , 28. , 20. , 34. , 51. ,\n",
       "        3. , 21. ,  nan,  nan,  nan, 33. ,  nan, 44. ,  nan, 34. , 18. ,\n",
       "       30. , 10. ,  nan, 21. , 29. , 28. , 18. ,  nan, 28. , 19. ,  nan,\n",
       "       32. , 28. ,  nan, 42. , 17. , 50. , 14. , 21. , 24. , 64. , 31. ,\n",
       "       45. , 20. , 25. , 28. ,  nan,  4. , 13. , 34. ,  5. , 52. , 36. ,\n",
       "        nan, 30. , 49. ,  nan, 29. , 65. ,  nan, 50. ,  nan, 48. , 34. ,\n",
       "       47. , 48. ,  nan, 38. ,  nan, 56. ,  nan,  1. ,  nan, 38. , 33. ,\n",
       "       23. , 22. ,  nan, 34. , 29. , 22. ,  2. ,  9. ,  nan, 50. , 63. ,\n",
       "       25. ,  nan, 35. , 58. , 30. ,  9. ,  nan, 21. , 55. , 71. , 21. ,\n",
       "        nan, 54. ,  nan, 25. , 24. , 17. , 21. ,  nan, 37. , 16. , 18. ,\n",
       "       33. ,  nan, 28. , 26. , 29. ,  nan, 36. , 54. , 24. , 47. , 34. ,\n",
       "        nan, 36. , 32. , 30. , 22. ,  nan, 44. ,  nan, 40.5, 50. ,  nan,\n",
       "       39. , 23. ,  2. ,  nan, 17. ,  nan, 30. ,  7. , 45. , 30. ,  nan,\n",
       "       22. , 36. ,  9. , 11. , 32. , 50. , 64. , 19. ,  nan, 33. ,  8. ,\n",
       "       17. , 27. ,  nan, 22. , 22. , 62. , 48. ,  nan, 39. , 36. ,  nan,\n",
       "       40. , 28. ,  nan,  nan, 24. , 19. , 29. ,  nan, 32. , 62. , 53. ,\n",
       "       36. ,  nan, 16. , 19. , 34. , 39. ,  nan, 32. , 25. , 39. , 54. ,\n",
       "       36. ,  nan, 18. , 47. , 60. , 22. ,  nan, 35. , 52. , 47. ,  nan,\n",
       "       37. , 36. ,  nan, 49. ,  nan, 49. , 24. ,  nan,  nan, 44. , 35. ,\n",
       "       36. , 30. , 27. , 22. , 40. , 39. ,  nan,  nan,  nan, 35. , 24. ,\n",
       "       34. , 26. ,  4. , 26. , 27. , 42. , 20. , 21. , 21. , 61. , 57. ,\n",
       "       21. , 26. ,  nan, 80. , 51. , 32. ,  nan,  9. , 28. , 32. , 31. ,\n",
       "       41. ,  nan, 20. , 24. ,  2. ,  nan,  1. , 48. , 19. , 56. ,  nan,\n",
       "       23. ,  nan, 18. , 21. ,  nan, 18. , 24. ,  nan, 32. , 23. , 58. ,\n",
       "       50. , 40. , 47. , 36. , 20. , 32. , 25. ,  nan, 43. ,  nan, 40. ,\n",
       "       31. , 70. , 31. ,  nan, 18. , 24.5, 18. , 43. , 36. ,  nan, 27. ,\n",
       "       20. , 14. , 60. , 25. , 14. , 19. , 18. , 15. , 31. ,  4. ,  nan,\n",
       "       25. , 60. , 52. , 44. ,  nan, 49. , 42. , 18. , 35. , 18. , 25. ,\n",
       "       26. , 39. , 45. , 42. , 22. ,  nan, 24. ,  nan, 48. , 29. , 52. ,\n",
       "       19. , 38. , 27. ,  nan, 33. ,  6. , 17. , 34. , 50. , 27. , 20. ,\n",
       "       30. ,  nan, 25. , 25. , 29. , 11. ,  nan, 23. , 23. , 28.5, 48. ,\n",
       "       35. ,  nan,  nan,  nan, 36. , 21. , 24. , 31. , 70. , 16. , 30. ,\n",
       "       19. , 31. ,  4. ,  6. , 33. , 23. , 48. ,  1. , 28. , 18. , 34. ,\n",
       "       33. ,  nan, 41. , 20. , 36. , 16. , 51. ,  nan, 30.5,  nan, 32. ,\n",
       "       24. , 48. , 57. ,  nan, 54. , 18. ,  nan,  5. ,  nan, 43. , 13. ,\n",
       "       17. , 29. ,  nan, 25. , 25. , 18. ,  8. ,  1. , 46. ,  nan, 16. ,\n",
       "        nan,  nan, 25. , 39. , 49. , 31. , 30. , 30. , 34. , 31. , 11. ,\n",
       "        1. , 27. , 31. , 39. , 18. , 39. , 33. , 26. , 39. , 35. ,  6. ,\n",
       "       30.5,  nan, 23. , 31. , 43. , 10. , 52. , 27. , 38. , 27. ,  2. ,\n",
       "        nan,  nan,  1. ,  nan, 62. , 15. ,  1. ,  nan, 23. , 18. , 39. ,\n",
       "       21. ,  nan, 32. ,  nan, 20. , 16. , 30. , 34.5, 17. , 42. ,  nan,\n",
       "       35. , 28. ,  nan,  4. , 74. ,  9. , 16. , 44. , 18. , 45. , 51. ,\n",
       "       24. ,  nan, 41. , 21. , 48. ,  nan, 24. , 42. , 27. , 31. ,  nan,\n",
       "        4. , 26. , 47. , 33. , 47. , 28. , 15. , 20. , 19. ,  nan, 56. ,\n",
       "       25. , 33. , 22. , 28. , 25. , 39. , 27. , 19. ,  nan, 26. , 32. ])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(df['Age']<1,1,df['Age']) #esto tambien funciona y es mas rapido pero es \"menos de progamacion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    714.000000\n",
       "mean      29.701681\n",
       "std       14.521395\n",
       "min        1.000000\n",
       "25%       20.125000\n",
       "50%       28.000000\n",
       "75%       38.000000\n",
       "max       80.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ahora se cambiar el tipo de datos debido a que es flotante \n",
    "df['Age']=df['Age'].apply(lambda row:int(str(row).split('.')[0] )if '.' in str(row) else row) \n",
    "#este codigo convierte en str los datos de row con el split parte el str y dice que se quee conla parte izquierda [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22., 38., 26., 35., nan, 54.,  2., 27., 14.,  4., 58., 20., 39.,\n",
       "       55., 31., 34., 15., 28.,  8., 19., 40., 66., 42., 21., 18.,  3.,\n",
       "        7., 49., 29., 65.,  5., 11., 45., 17., 32., 16., 25.,  1., 30.,\n",
       "       33., 23., 24., 46., 59., 71., 37., 47., 70., 12.,  9., 36., 51.,\n",
       "       44., 61., 56., 50., 62., 41., 52., 63., 43., 60., 10., 64., 13.,\n",
       "       48., 53., 57., 80.,  6., 74.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'].unique() #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hay otra forma de hacerlo\n",
    "df['Age']=df['Age'].fillna(0)\n",
    "df['Age']=df['Age'].astype(int)\n",
    "df['Age'].replace(0,np.nan) \n",
    "#esta forma se puede hacer quitando los nan y es valida, pero en la vida real ouede tener algun problema "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test de granularidad: grueso o fino\n",
    "si te vas a fijar el conjunto de datos o en una fila en concreto, es decir, grueso seria todo el conjunto de datos si es fina es algo mas concreto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
