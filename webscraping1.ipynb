{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron 0 elementos que podrían ser planes\n",
      "Se han extraído 0 planes y se han guardado en 'planes_infantiles.csv'\n",
      "Intentando con método alternativo...\n",
      "HTML guardado en 'pagina_planes.html' para análisis manual\n",
      "Plan encontrado: Teatro\n",
      "Plan encontrado: Parques\n",
      "Plan encontrado: Parques de Ocio\n",
      "Plan encontrado: Rutas\n",
      "Plan encontrado: Museos\n",
      "Plan encontrado: PARQUES\n",
      "Plan encontrado: TEATRO\n",
      "Plan encontrado: PARQUES DE OCIO\n",
      "Plan encontrado: MUSEOS\n",
      "Plan encontrado: RUTAS\n",
      "Plan encontrado: ESCAPADAS\n",
      "Se han extraído 6 planes y se han guardado en 'planes_infantiles_alt.csv'\n",
      "Obteniendo detalles del plan: Teatro\n",
      "Obteniendo detalles del plan: Parques\n",
      "Obteniendo detalles del plan: Parques de Ocio\n",
      "Obteniendo detalles del plan: Rutas\n",
      "Obteniendo detalles del plan: Museos\n",
      "Obteniendo detalles del plan: ESCAPADAS\n",
      "Se han extraído los detalles de 6 planes y se han guardado en 'detalles_planes_infantiles.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def scrape_planinfantil():\n",
    "    \"\"\"\n",
    "    Función para hacer web scraping de la página https://www.planinfantil.es/planes/\n",
    "    Extrae información sobre los planes infantiles disponibles\n",
    "    \"\"\"\n",
    "    # URL de la página\n",
    "    url = \"https://www.planinfantil.es/planes/\"\n",
    "    \n",
    "    # Headers para simular un navegador y evitar bloqueos\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "        'Accept-Language': 'es-ES,es;q=0.9'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Realizamos la petición HTTP\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        # Verificamos si la petición fue exitosa\n",
    "        if response.status_code == 200:\n",
    "            # Parseamos el contenido HTML con BeautifulSoup\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Lista para almacenar los planes\n",
    "            planes = []\n",
    "            \n",
    "            # Inspeccionando la página real, ajustamos los selectores\n",
    "            # Buscamos los planes en div con clase que contiene \"plan-item\" o similares\n",
    "            articulos = soup.select('div.elementor-post')\n",
    "            \n",
    "            print(f\"Se encontraron {len(articulos)} elementos que podrían ser planes\")\n",
    "            \n",
    "            for articulo in articulos:\n",
    "                try:\n",
    "                    # Extraemos la información de cada plan con los selectores correctos\n",
    "                    titulo = articulo.select_one('h3.elementor-post__title a').text.strip() if articulo.select_one('h3.elementor-post__title a') else \"No disponible\"\n",
    "                    \n",
    "                    # La descripción puede estar en varias clases, intentamos encontrarla\n",
    "                    descripcion_elem = articulo.select_one('div.elementor-post__excerpt p')\n",
    "                    descripcion = descripcion_elem.text.strip() if descripcion_elem else \"No disponible\"\n",
    "                    \n",
    "                    # Buscamos información de fecha y ubicación\n",
    "                    meta_data = articulo.select('div.elementor-post__meta-data span')\n",
    "                    fecha = meta_data[0].text.strip() if len(meta_data) > 0 else \"No disponible\"\n",
    "                    ubicacion = meta_data[1].text.strip() if len(meta_data) > 1 else \"No disponible\"\n",
    "                    \n",
    "                    # Extraer la URL de la imagen\n",
    "                    img_tag = articulo.select_one('div.elementor-post__thumbnail img')\n",
    "                    imagen_url = img_tag['src'] if img_tag and 'src' in img_tag.attrs else \"No disponible\"\n",
    "                    \n",
    "                    # Extraer el enlace para más detalles\n",
    "                    link_tag = articulo.select_one('a.elementor-post__thumbnail__link') or articulo.select_one('h3.elementor-post__title a')\n",
    "                    enlace = link_tag['href'] if link_tag and 'href' in link_tag.attrs else \"No disponible\"\n",
    "                    \n",
    "                    # Imprimimos para debug\n",
    "                    print(f\"Plan encontrado: {titulo}\")\n",
    "                    \n",
    "                    # Guardamos los datos en un diccionario\n",
    "                    plan = {\n",
    "                        'Título': titulo,\n",
    "                        'Descripción': descripcion,\n",
    "                        'Fecha': fecha,\n",
    "                        'Ubicación': ubicacion,\n",
    "                        'Imagen URL': imagen_url,\n",
    "                        'Enlace': enlace\n",
    "                    }\n",
    "                    \n",
    "                    planes.append(plan)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error al procesar un artículo: {str(e)}\")\n",
    "            \n",
    "            # Creamos un DataFrame con la información extraída\n",
    "            df = pd.DataFrame(planes)\n",
    "            \n",
    "            # Guardamos los datos en un archivo CSV\n",
    "            df.to_csv('planes_infantiles.csv', index=False, encoding='utf-8-sig')\n",
    "            \n",
    "            print(f\"Se han extraído {len(planes)} planes y se han guardado en 'planes_infantiles.csv'\")\n",
    "            return df\n",
    "            \n",
    "        else:\n",
    "            print(f\"Error al acceder a la página. Código de estado: {response.status_code}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error durante el web scraping: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Alternativa usando otra aproximación más general para detectar los elementos\n",
    "def scrape_planinfantil_alternativo():\n",
    "    \"\"\"\n",
    "    Aproximación alternativa para extraer datos de la página\n",
    "    \"\"\"\n",
    "    url = \"https://www.planinfantil.es/planes/\"\n",
    "    \n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Guardamos el HTML para análisis\n",
    "            with open(\"pagina_planes.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(soup.prettify())\n",
    "                \n",
    "            print(\"HTML guardado en 'pagina_planes.html' para análisis manual\")\n",
    "            \n",
    "            # Buscamos todos los enlaces que podrían llevar a planes\n",
    "            enlaces = soup.select('a[href*=\"planinfantil.es/planes/\"]')\n",
    "            \n",
    "            planes = []\n",
    "            \n",
    "            for enlace in enlaces:\n",
    "                # Excluimos los enlaces de navegación, categorías, etc.\n",
    "                if \"category\" in enlace['href'] or \"page\" in enlace['href']:\n",
    "                    continue\n",
    "                    \n",
    "                titulo = enlace.text.strip()\n",
    "                if not titulo:  # Si el enlace no tiene texto, buscar en elementos padre o hijos\n",
    "                    titulo_elem = enlace.select_one('h3') or enlace.parent.select_one('h3')\n",
    "                    if titulo_elem:\n",
    "                        titulo = titulo_elem.text.strip()\n",
    "                \n",
    "                # Solo añadir si el título no está vacío y el enlace no es la misma página\n",
    "                if titulo and enlace['href'] != url:\n",
    "                    plan = {\n",
    "                        'Título': titulo,\n",
    "                        'Enlace': enlace['href']\n",
    "                    }\n",
    "                    planes.append(plan)\n",
    "                    print(f\"Plan encontrado: {titulo}\")\n",
    "            \n",
    "            # Creamos un DataFrame con la información extraída\n",
    "            df = pd.DataFrame(planes)\n",
    "            \n",
    "            if not df.empty:\n",
    "                # Eliminamos duplicados basados en el enlace\n",
    "                df = df.drop_duplicates(subset=['Enlace'])\n",
    "                \n",
    "                # Guardamos los datos en un archivo CSV\n",
    "                df.to_csv('planes_infantiles_alt.csv', index=False, encoding='utf-8-sig')\n",
    "                \n",
    "                print(f\"Se han extraído {len(df)} planes y se han guardado en 'planes_infantiles_alt.csv'\")\n",
    "                return df\n",
    "            else:\n",
    "                print(\"No se encontraron planes en la página\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"Error al acceder a la página. Código de estado: {response.status_code}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error durante el web scraping: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Función para extraer información detallada de cada plan\n",
    "def obtener_detalles_plan(url):\n",
    "    \"\"\"\n",
    "    Función para extraer información detallada de un plan específico\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Extrae la información detallada del plan\n",
    "            titulo = soup.select_one('h1.elementor-heading-title') or soup.select_one('h1')\n",
    "            titulo = titulo.text.strip() if titulo else \"No disponible\"\n",
    "            \n",
    "            # Buscar la descripción en varios posibles contenedores\n",
    "            descripcion_elem = soup.select_one('div.elementor-widget-container p') or soup.select_one('div.elementor-text-editor')\n",
    "            descripcion_completa = descripcion_elem.text.strip() if descripcion_elem else \"No disponible\"\n",
    "            \n",
    "            # Intentar encontrar más información\n",
    "            info_adicional = {}\n",
    "            \n",
    "            # Buscar todos los elementos que puedan contener información relevante\n",
    "            elementos_info = soup.select('div.elementor-text-editor')\n",
    "            \n",
    "            for elem in elementos_info:\n",
    "                texto = elem.text.strip()\n",
    "                \n",
    "                # Intentar identificar información relevante\n",
    "                if \"precio\" in texto.lower():\n",
    "                    info_adicional[\"Precio\"] = texto\n",
    "                elif \"horario\" in texto.lower():\n",
    "                    info_adicional[\"Horario\"] = texto\n",
    "                elif \"edad\" in texto.lower():\n",
    "                    info_adicional[\"Edad recomendada\"] = texto\n",
    "            \n",
    "            detalles = {\n",
    "                'Título': titulo,\n",
    "                'Descripción completa': descripcion_completa,\n",
    "                **info_adicional\n",
    "            }\n",
    "            \n",
    "            return detalles\n",
    "            \n",
    "        else:\n",
    "            print(f\"Error al acceder a la página de detalles. Código de estado: {response.status_code}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error al obtener detalles del plan: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Ejemplo de uso combinado\n",
    "if __name__ == \"__main__\":\n",
    "    # Intentamos primero con el método principal\n",
    "    df_planes = scrape_planinfantil()\n",
    "    \n",
    "    # Si no funciona, intentamos con el método alternativo\n",
    "    if df_planes is None or df_planes.empty:\n",
    "        print(\"Intentando con método alternativo...\")\n",
    "        df_planes = scrape_planinfantil_alternativo()\n",
    "    \n",
    "    if df_planes is not None and not df_planes.empty:\n",
    "        # Para cada plan, obtenemos los detalles\n",
    "        detalles_planes = []\n",
    "        \n",
    "        for i, plan in df_planes.iterrows():\n",
    "            titulo = plan.get('Título', f\"Plan {i+1}\")\n",
    "            print(f\"Obteniendo detalles del plan: {titulo}\")\n",
    "            \n",
    "            # Solo procesamos los planes que tienen un enlace válido\n",
    "            if 'Enlace' in plan and plan['Enlace'] != \"No disponible\":\n",
    "                detalles = obtener_detalles_plan(plan['Enlace'])\n",
    "                \n",
    "                if detalles:\n",
    "                    detalles_planes.append(detalles)\n",
    "                    \n",
    "                # Esperamos un poco entre peticiones para evitar sobrecarga\n",
    "                time.sleep(2)\n",
    "        \n",
    "        # Guardamos los detalles en otro archivo CSV\n",
    "        if detalles_planes:\n",
    "            df_detalles = pd.DataFrame(detalles_planes)\n",
    "            df_detalles.to_csv('detalles_planes_infantiles.csv', index=False, encoding='utf-8-sig')\n",
    "            print(f\"Se han extraído los detalles de {len(detalles_planes)} planes y se han guardado en 'detalles_planes_infantiles.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Título': 'Teatro infantil de Madrid',\n",
       "  'Descripción completa': 'No disponible'},\n",
       " {'Título': 'Parques infantiles de Madrid',\n",
       "  'Descripción completa': 'No disponible'},\n",
       " {'Título': 'Parques de Ocio', 'Descripción completa': 'No disponible'},\n",
       " {'Título': 'Rutas', 'Descripción completa': 'No disponible'},\n",
       " {'Título': 'Museos', 'Descripción completa': 'No disponible'},\n",
       " {'Título': 'Escapadas', 'Descripción completa': 'No disponible'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detalles_planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando web scraping básico...\n",
      "Se encontraron 0 elementos que podrían ser planes\n",
      "Se han extraído y estructurado 0 planes y se han guardado en 'planes_infantiles_estructurados.csv'\n",
      "\n",
      "Realizando web scraping detallado...\n",
      "Se encontraron 0 elementos que podrían ser planes\n",
      "Se han extraído y estructurado 0 planes detallados y se han guardado en 'planes_infantiles_detallados.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import uuid\n",
    "\n",
    "def categorizar_evento(titulo, descripcion):\n",
    "    \"\"\"\n",
    "    Función para categorizar un evento basado en su título y descripción\n",
    "    \"\"\"\n",
    "    titulo_desc = (titulo + \" \" + descripcion).lower()\n",
    "    \n",
    "    if any(palabra in titulo_desc for palabra in ['taller', 'manualidad', 'crear', 'construir', 'artesanía']):\n",
    "        return 'Talleres'\n",
    "    elif any(palabra in titulo_desc for palabra in ['salud', 'bienestar', 'médico', 'terapia', 'hospital']):\n",
    "        return 'Salud'\n",
    "    elif any(palabra in titulo_desc for palabra in ['museo', 'teatro', 'concierto', 'exposición', 'arte', 'cultura', 'música']):\n",
    "        return 'Cultural'\n",
    "    elif any(palabra in titulo_desc for palabra in ['deporte', 'fútbol', 'baloncesto', 'natación', 'carrera', 'competición', 'olimpiada']):\n",
    "        return 'Deportiva'\n",
    "    else:\n",
    "        return 'No especificada'\n",
    "\n",
    "def determinar_discapacidad(titulo, descripcion):\n",
    "    \"\"\"\n",
    "    Función para determinar si el evento está adaptado para alguna discapacidad\n",
    "    \"\"\"\n",
    "    titulo_desc = (titulo + \" \" + descripcion).lower()\n",
    "    \n",
    "    if any(palabra in titulo_desc for palabra in ['visual', 'ciego', 'invidente', 'baja visión']):\n",
    "        return 'Visual'\n",
    "    elif any(palabra in titulo_desc for palabra in ['auditivo', 'sordo', 'hipoacusia']):\n",
    "        return 'Auditiva'\n",
    "    elif any(palabra in titulo_desc for palabra in ['motor', 'motriz', 'silla de ruedas', 'movilidad reducida']):\n",
    "        return 'Motora'\n",
    "    elif any(palabra in titulo_desc for palabra in ['accesible', 'adaptado', 'inclusiv', 'discapacidad']):\n",
    "        return 'Adaptado - no especificada'\n",
    "    else:\n",
    "        return 'Ninguna'\n",
    "\n",
    "def extraer_costo(texto):\n",
    "    \"\"\"\n",
    "    Función para extraer el costo de un texto\n",
    "    \"\"\"\n",
    "    # Patrones para buscar precios en formato español\n",
    "    patrones = [\n",
    "        r'(\\d+[,.]?\\d*)\\s*€',  # 10 €, 10,50 €\n",
    "        r'(\\d+[,.]?\\d*)\\s*euros',  # 10 euros, 10,50 euros\n",
    "        r'precio[:\\s]*(\\d+[,.]?\\d*)',  # precio: 10, precio 10,50\n",
    "        r'cuesta[:\\s]*(\\d+[,.]?\\d*)',  # cuesta: 10, cuesta 10,50\n",
    "    ]\n",
    "    \n",
    "    texto_lower = texto.lower()\n",
    "    \n",
    "    if 'gratis' in texto_lower or 'gratuito' in texto_lower or 'libre' in texto_lower:\n",
    "        return '0 €'\n",
    "    \n",
    "    for patron in patrones:\n",
    "        match = re.search(patron, texto_lower)\n",
    "        if match:\n",
    "            return f\"{match.group(1)} €\"\n",
    "    \n",
    "    return 'No especificado'\n",
    "\n",
    "def determinar_edad(texto):\n",
    "    \"\"\"\n",
    "    Función para determinar la edad dirigida\n",
    "    \"\"\"\n",
    "    # Patrones para buscar edades\n",
    "    patrones = [\n",
    "        r'(\\d+)[-\\s]*(\\d+)\\s*años',  # 3-12 años, 3 a 12 años\n",
    "        r'de\\s*(\\d+)\\s*a\\s*(\\d+)\\s*años',  # de 3 a 12 años\n",
    "        r'edad[:\\s]*(\\d+)[-\\s]*(\\d+)',  # edad: 3-12, edad 3-12\n",
    "        r'(\\d+)\\+\\s*años',  # 3+ años\n",
    "        r'mayores de (\\d+)',  # mayores de 3\n",
    "        r'a partir de (\\d+)',  # a partir de 3\n",
    "    ]\n",
    "    \n",
    "    texto_lower = texto.lower()\n",
    "    \n",
    "    for patron in patrones:\n",
    "        match = re.search(patron, texto_lower)\n",
    "        if match:\n",
    "            if len(match.groups()) == 2:\n",
    "                return f\"{match.group(1)}-{match.group(2)} años\"\n",
    "            else:\n",
    "                return f\"{match.group(1)}+ años\"\n",
    "    \n",
    "    # Verificar términos comunes\n",
    "    if any(term in texto_lower for term in ['infantil', 'niños', 'pequeños']):\n",
    "        return '3-12 años'\n",
    "    elif any(term in texto_lower for term in ['adolescente', 'jóvenes', 'juvenil']):\n",
    "        return '12-18 años'\n",
    "    elif any(term in texto_lower for term in ['familiar', 'familia']):\n",
    "        return 'Todas las edades'\n",
    "    \n",
    "    return 'No especificado'\n",
    "\n",
    "def determinar_modalidad(texto):\n",
    "    \"\"\"\n",
    "    Función para determinar si el evento es en interior o exterior\n",
    "    \"\"\"\n",
    "    texto_lower = texto.lower()\n",
    "    \n",
    "    interior = ['interior', 'sala', 'aula', 'museo', 'teatro', 'centro', 'edificio']\n",
    "    exterior = ['exterior', 'parque', 'aire libre', 'jardín', 'piscina', 'playa', 'montaña', 'naturaleza']\n",
    "    \n",
    "    if any(palabra in texto_lower for palabra in exterior):\n",
    "        return 'Exterior'\n",
    "    elif any(palabra in texto_lower for palabra in interior):\n",
    "        return 'Interior'\n",
    "    else:\n",
    "        return 'No especificado'\n",
    "\n",
    "def determinar_min_integrantes(texto):\n",
    "    \"\"\"\n",
    "    Función para determinar el mínimo de integrantes\n",
    "    \"\"\"\n",
    "    patrones = [\n",
    "        r'mínimo\\s*(\\d+)\\s*persona',  # mínimo 5 personas\n",
    "        r'grupo[s]?\\s*de\\s*(\\d+)',  # grupos de 5\n",
    "        r'(\\d+)\\s*participante[s]?\\s*mínimo',  # 5 participantes mínimo\n",
    "    ]\n",
    "    \n",
    "    texto_lower = texto.lower()\n",
    "    \n",
    "    for patron in patrones:\n",
    "        match = re.search(patron, texto_lower)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    \n",
    "    if 'individual' in texto_lower or 'personal' in texto_lower:\n",
    "        return '1'\n",
    "    elif 'grupo' in texto_lower or 'equipo' in texto_lower:\n",
    "        return '2'\n",
    "    \n",
    "    return 'No especificado'\n",
    "\n",
    "def scrape_planinfantil_estructurado():\n",
    "    \"\"\"\n",
    "    Función para hacer web scraping de la página https://www.planinfantil.es/planes/\n",
    "    y estructurar los datos según lo requerido\n",
    "    \"\"\"\n",
    "    # URL de la página\n",
    "    url = \"https://www.planinfantil.es/planes/\"\n",
    "    \n",
    "    # Headers para simular un navegador y evitar bloqueos\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "        'Accept-Language': 'es-ES,es;q=0.9'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Realizamos la petición HTTP\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        # Verificamos si la petición fue exitosa\n",
    "        if response.status_code == 200:\n",
    "            # Parseamos el contenido HTML con BeautifulSoup\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Lista para almacenar los planes con la estructura requerida\n",
    "            planes_estructurados = []\n",
    "            \n",
    "            # Buscamos los planes en div con clase que contiene \"plan-item\" o similares\n",
    "            articulos = soup.select('div.elementor-post')\n",
    "            \n",
    "            print(f\"Se encontraron {len(articulos)} elementos que podrían ser planes\")\n",
    "            \n",
    "            contador = 1\n",
    "            for articulo in articulos:\n",
    "                try:\n",
    "                    # Generamos un ID único\n",
    "                    id_evento = str(uuid.uuid4())[:8]\n",
    "                    \n",
    "                    # Extraemos la información básica\n",
    "                    titulo_elem = articulo.select_one('h3.elementor-post__title a')\n",
    "                    titulo = titulo_elem.text.strip() if titulo_elem else \"No disponible\"\n",
    "                    \n",
    "                    descripcion_elem = articulo.select_one('div.elementor-post__excerpt p')\n",
    "                    descripcion = descripcion_elem.text.strip() if descripcion_elem else \"No disponible\"\n",
    "                    \n",
    "                    # Combinamos título y descripción para análisis\n",
    "                    texto_completo = f\"{titulo} {descripcion}\"\n",
    "                    \n",
    "                    # Extraemos o inferimos el resto de la información\n",
    "                    meta_data = articulo.select('div.elementor-post__meta-data span')\n",
    "                    ubicacion = meta_data[1].text.strip() if len(meta_data) > 1 else \"No especificado\"\n",
    "                    \n",
    "                    # Categorización según el contenido\n",
    "                    categoria = categorizar_evento(titulo, descripcion)\n",
    "                    discapacidad = determinar_discapacidad(titulo, descripcion)\n",
    "                    costo = extraer_costo(texto_completo)\n",
    "                    edad_dirigida = determinar_edad(texto_completo)\n",
    "                    modalidad = determinar_modalidad(texto_completo)\n",
    "                    min_integrantes = determinar_min_integrantes(texto_completo)\n",
    "                    \n",
    "                    # Guardamos los datos en un diccionario con la estructura requerida\n",
    "                    plan_estructurado = {\n",
    "                        'id_evento': id_evento,\n",
    "                        'nombre_evento': titulo,\n",
    "                        'categoria': categoria,\n",
    "                        'discapacidad': discapacidad,\n",
    "                        'ubicacion': ubicacion,\n",
    "                        'costo': costo,\n",
    "                        'edad_dirigida': edad_dirigida,\n",
    "                        'min_integrantes': min_integrantes,\n",
    "                        'modalidad': modalidad\n",
    "                    }\n",
    "                    \n",
    "                    planes_estructurados.append(plan_estructurado)\n",
    "                    print(f\"Plan {contador} procesado: {titulo}\")\n",
    "                    contador += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error al procesar un artículo: {str(e)}\")\n",
    "            \n",
    "            # Creamos un DataFrame con la información estructurada\n",
    "            df = pd.DataFrame(planes_estructurados)\n",
    "            \n",
    "            # Guardamos los datos en un archivo CSV\n",
    "            df.to_csv('planes_infantiles_estructurados.csv', index=False, encoding='utf-8-sig')\n",
    "            \n",
    "            print(f\"Se han extraído y estructurado {len(planes_estructurados)} planes y se han guardado en 'planes_infantiles_estructurados.csv'\")\n",
    "            return df\n",
    "            \n",
    "        else:\n",
    "            print(f\"Error al acceder a la página. Código de estado: {response.status_code}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error durante el web scraping: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Versión alternativa que obtiene más detalles navegando a cada página de evento\n",
    "def scrape_planinfantil_estructurado_detallado():\n",
    "    \"\"\"\n",
    "    Función para hacer web scraping más detallado, visitando cada página de evento\n",
    "    \"\"\"\n",
    "    # URL de la página\n",
    "    url = \"https://www.planinfantil.es/planes/\"\n",
    "    \n",
    "    # Headers para simular un navegador\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Realizamos la petición HTTP\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Lista para almacenar los planes con la estructura requerida\n",
    "            planes_estructurados = []\n",
    "            \n",
    "            # Buscamos los enlaces a las páginas de eventos\n",
    "            articulos = soup.select('div.elementor-post')\n",
    "            \n",
    "            print(f\"Se encontraron {len(articulos)} elementos que podrían ser planes\")\n",
    "            \n",
    "            contador = 1\n",
    "            for articulo in articulos:\n",
    "                try:\n",
    "                    # Extraemos información básica\n",
    "                    titulo_elem = articulo.select_one('h3.elementor-post__title a')\n",
    "                    nombre_evento = titulo_elem.text.strip() if titulo_elem else \"No disponible\"\n",
    "                    \n",
    "                    # Extraer el enlace para más detalles\n",
    "                    link_tag = articulo.select_one('a.elementor-post__thumbnail__link') or articulo.select_one('h3.elementor-post__title a')\n",
    "                    enlace = link_tag['href'] if link_tag and 'href' in link_tag.attrs else None\n",
    "                    \n",
    "                    # Si no hay enlace, continuamos con el siguiente\n",
    "                    if not enlace:\n",
    "                        print(f\"No se encontró enlace para: {nombre_evento}\")\n",
    "                        continue\n",
    "                    \n",
    "                    print(f\"Obteniendo detalles de: {nombre_evento} ({enlace})\")\n",
    "                    \n",
    "                    # Visitamos la página del evento para obtener más detalles\n",
    "                    try:\n",
    "                        detalle_response = requests.get(enlace, headers=headers)\n",
    "                        if detalle_response.status_code == 200:\n",
    "                            detalle_soup = BeautifulSoup(detalle_response.content, 'html.parser')\n",
    "                            \n",
    "                            # Extraemos toda la información textual de la página\n",
    "                            texto_completo = detalle_soup.get_text()\n",
    "                            \n",
    "                            # Generamos un ID único\n",
    "                            id_evento = str(uuid.uuid4())[:8]\n",
    "                            \n",
    "                            # Meta datos\n",
    "                            meta_data = articulo.select('div.elementor-post__meta-data span')\n",
    "                            ubicacion = meta_data[1].text.strip() if len(meta_data) > 1 else \"No especificado\"\n",
    "                            \n",
    "                            # Analizamos el texto para extraer/inferir información\n",
    "                            categoria = categorizar_evento(nombre_evento, texto_completo)\n",
    "                            discapacidad = determinar_discapacidad(nombre_evento, texto_completo)\n",
    "                            costo = extraer_costo(texto_completo)\n",
    "                            edad_dirigida = determinar_edad(texto_completo)\n",
    "                            modalidad = determinar_modalidad(texto_completo)\n",
    "                            min_integrantes = determinar_min_integrantes(texto_completo)\n",
    "                            \n",
    "                            # Guardamos los datos en un diccionario con la estructura requerida\n",
    "                            plan_estructurado = {\n",
    "                                'id_evento': id_evento,\n",
    "                                'nombre_evento': nombre_evento,\n",
    "                                'categoria': categoria,\n",
    "                                'discapacidad': discapacidad,\n",
    "                                'ubicacion': ubicacion,\n",
    "                                'costo': costo,\n",
    "                                'edad_dirigida': edad_dirigida,\n",
    "                                'min_integrantes': min_integrantes,\n",
    "                                'modalidad': modalidad\n",
    "                            }\n",
    "                            \n",
    "                            planes_estructurados.append(plan_estructurado)\n",
    "                            print(f\"Plan {contador} procesado: {nombre_evento}\")\n",
    "                            \n",
    "                        else:\n",
    "                            print(f\"Error al acceder a la página del evento: {enlace}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error al obtener detalles de {nombre_evento}: {str(e)}\")\n",
    "                    \n",
    "                    # Esperamos para no sobrecargar el servidor\n",
    "                    time.sleep(2)\n",
    "                    contador += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error al procesar un artículo: {str(e)}\")\n",
    "            \n",
    "            # Creamos un DataFrame con la información estructurada\n",
    "            df = pd.DataFrame(planes_estructurados)\n",
    "            \n",
    "            # Guardamos los datos en un archivo CSV\n",
    "            df.to_csv('planes_infantiles_detallados.csv', index=False, encoding='utf-8-sig')\n",
    "            \n",
    "            print(f\"Se han extraído y estructurado {len(planes_estructurados)} planes detallados y se han guardado en 'planes_infantiles_detallados.csv'\")\n",
    "            return df\n",
    "            \n",
    "        else:\n",
    "            print(f\"Error al acceder a la página. Código de estado: {response.status_code}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error durante el web scraping: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Ejecutar el código\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Iniciando web scraping básico...\")\n",
    "    df_basico = scrape_planinfantil_estructurado()\n",
    "    \n",
    "    if df_basico is None or df_basico.empty:\n",
    "        print(\"\\nRealizando web scraping detallado...\")\n",
    "        df_detallado = scrape_planinfantil_estructurado_detallado()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando web scraping con Selenium...\n",
      "Accediendo a https://www.planinfantil.es/planes/...\n",
      "Título de la página: Planes con niños en Madrid - planinfantil.es\n",
      "HTML guardado en 'pagina_selenium.html'\n",
      "Buscando eventos en la página...\n",
      "Se encontraron 1 elementos con el selector 'article'\n",
      "Evento 1: PARQUES - URL: https://www.planinfantil.es/planes/parques/\n",
      "Se han extraído y estructurado 1 eventos y se han guardado en 'planes_infantiles_selenium.csv'\n",
      "\n",
      "Primeros 5 eventos extraídos:\n",
      "  id_evento nombre_evento categoria discapacidad ubicacion            costo  \\\n",
      "0  6bd28bb9       PARQUES  Talleres      Ninguna    Madrid  No especificado   \n",
      "\n",
      "  edad_dirigida min_integrantes modalidad  \n",
      "0     3-12 años               1  Exterior  \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import uuid\n",
    "\n",
    "def inicializar_driver():\n",
    "    \"\"\"\n",
    "    Inicializa y configura el driver de Selenium\n",
    "    \"\"\"\n",
    "    # Configuramos opciones para Chrome\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Ejecutar en modo headless (sin interfaz gráfica)\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    \n",
    "    # Inicializamos el driver\n",
    "    try:\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "        return driver\n",
    "    except Exception as e:\n",
    "        print(f\"Error al inicializar el driver: {str(e)}\")\n",
    "        \n",
    "        # Alternativa si ChromeDriverManager falla\n",
    "        try:\n",
    "            driver = webdriver.Chrome(options=chrome_options)\n",
    "            return driver\n",
    "        except Exception as e2:\n",
    "            print(f\"Error alternativo: {str(e2)}\")\n",
    "            return None\n",
    "\n",
    "def categorizar_evento(titulo, descripcion):\n",
    "    \"\"\"\n",
    "    Función para categorizar un evento basado en su título y descripción\n",
    "    \"\"\"\n",
    "    titulo_desc = (titulo + \" \" + descripcion).lower()\n",
    "    \n",
    "    if any(palabra in titulo_desc for palabra in ['taller', 'manualidad', 'crear', 'construir', 'artesanía']):\n",
    "        return 'Talleres'\n",
    "    elif any(palabra in titulo_desc for palabra in ['salud', 'bienestar', 'médico', 'terapia', 'hospital']):\n",
    "        return 'Salud'\n",
    "    elif any(palabra in titulo_desc for palabra in ['museo', 'teatro', 'concierto', 'exposición', 'arte', 'cultura', 'música']):\n",
    "        return 'Cultural'\n",
    "    elif any(palabra in titulo_desc for palabra in ['deporte', 'fútbol', 'baloncesto', 'natación', 'carrera', 'competición', 'olimpiada']):\n",
    "        return 'Deportiva'\n",
    "    else:\n",
    "        return 'No especificada'\n",
    "\n",
    "def determinar_discapacidad(titulo, descripcion):\n",
    "    \"\"\"\n",
    "    Función para determinar si el evento está adaptado para alguna discapacidad\n",
    "    \"\"\"\n",
    "    titulo_desc = (titulo + \" \" + descripcion).lower()\n",
    "    \n",
    "    if any(palabra in titulo_desc for palabra in ['visual', 'ciego', 'invidente', 'baja visión']):\n",
    "        return 'Visual'\n",
    "    elif any(palabra in titulo_desc for palabra in ['auditivo', 'sordo', 'hipoacusia']):\n",
    "        return 'Auditiva'\n",
    "    elif any(palabra in titulo_desc for palabra in ['motor', 'motriz', 'silla de ruedas', 'movilidad reducida']):\n",
    "        return 'Motora'\n",
    "    elif any(palabra in titulo_desc for palabra in ['accesible', 'adaptado', 'inclusiv', 'discapacidad']):\n",
    "        return 'Adaptado - no especificada'\n",
    "    else:\n",
    "        return 'Ninguna'\n",
    "\n",
    "def extraer_costo(texto):\n",
    "    \"\"\"\n",
    "    Función para extraer el costo de un texto\n",
    "    \"\"\"\n",
    "    # Patrones para buscar precios en formato español\n",
    "    patrones = [\n",
    "        r'(\\d+[,.]?\\d*)\\s*€',  # 10 €, 10,50 €\n",
    "        r'(\\d+[,.]?\\d*)\\s*euros',  # 10 euros, 10,50 euros\n",
    "        r'precio[:\\s]*(\\d+[,.]?\\d*)',  # precio: 10, precio 10,50\n",
    "        r'cuesta[:\\s]*(\\d+[,.]?\\d*)',  # cuesta: 10, cuesta 10,50\n",
    "    ]\n",
    "    \n",
    "    texto_lower = texto.lower()\n",
    "    \n",
    "    if 'gratis' in texto_lower or 'gratuito' in texto_lower or 'libre' in texto_lower:\n",
    "        return '0 €'\n",
    "    \n",
    "    for patron in patrones:\n",
    "        match = re.search(patron, texto_lower)\n",
    "        if match:\n",
    "            return f\"{match.group(1)} €\"\n",
    "    \n",
    "    return 'No especificado'\n",
    "\n",
    "def determinar_edad(texto):\n",
    "    \"\"\"\n",
    "    Función para determinar la edad dirigida\n",
    "    \"\"\"\n",
    "    # Patrones para buscar edades\n",
    "    patrones = [\n",
    "        r'(\\d+)[-\\s]*(\\d+)\\s*años',  # 3-12 años, 3 a 12 años\n",
    "        r'de\\s*(\\d+)\\s*a\\s*(\\d+)\\s*años',  # de 3 a 12 años\n",
    "        r'edad[:\\s]*(\\d+)[-\\s]*(\\d+)',  # edad: 3-12, edad 3-12\n",
    "        r'(\\d+)\\+\\s*años',  # 3+ años\n",
    "        r'mayores de (\\d+)',  # mayores de 3\n",
    "        r'a partir de (\\d+)',  # a partir de 3\n",
    "    ]\n",
    "    \n",
    "    texto_lower = texto.lower()\n",
    "    \n",
    "    for patron in patrones:\n",
    "        match = re.search(patron, texto_lower)\n",
    "        if match:\n",
    "            if len(match.groups()) == 2:\n",
    "                return f\"{match.group(1)}-{match.group(2)} años\"\n",
    "            else:\n",
    "                return f\"{match.group(1)}+ años\"\n",
    "    \n",
    "    # Verificar términos comunes\n",
    "    if any(term in texto_lower for term in ['infantil', 'niños', 'pequeños']):\n",
    "        return '3-12 años'\n",
    "    elif any(term in texto_lower for term in ['adolescente', 'jóvenes', 'juvenil']):\n",
    "        return '12-18 años'\n",
    "    elif any(term in texto_lower for term in ['familiar', 'familia']):\n",
    "        return 'Todas las edades'\n",
    "    \n",
    "    return 'No especificado'\n",
    "\n",
    "def determinar_modalidad(texto):\n",
    "    \"\"\"\n",
    "    Función para determinar si el evento es en interior o exterior\n",
    "    \"\"\"\n",
    "    texto_lower = texto.lower()\n",
    "    \n",
    "    interior = ['interior', 'sala', 'aula', 'museo', 'teatro', 'centro', 'edificio']\n",
    "    exterior = ['exterior', 'parque', 'aire libre', 'jardín', 'piscina', 'playa', 'montaña', 'naturaleza']\n",
    "    \n",
    "    if any(palabra in texto_lower for palabra in exterior):\n",
    "        return 'Exterior'\n",
    "    elif any(palabra in texto_lower for palabra in interior):\n",
    "        return 'Interior'\n",
    "    else:\n",
    "        return 'No especificado'\n",
    "\n",
    "def determinar_min_integrantes(texto):\n",
    "    \"\"\"\n",
    "    Función para determinar el mínimo de integrantes\n",
    "    \"\"\"\n",
    "    patrones = [\n",
    "        r'mínimo\\s*(\\d+)\\s*persona',  # mínimo 5 personas\n",
    "        r'grupo[s]?\\s*de\\s*(\\d+)',  # grupos de 5\n",
    "        r'(\\d+)\\s*participante[s]?\\s*mínimo',  # 5 participantes mínimo\n",
    "    ]\n",
    "    \n",
    "    texto_lower = texto.lower()\n",
    "    \n",
    "    for patron in patrones:\n",
    "        match = re.search(patron, texto_lower)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    \n",
    "    if 'individual' in texto_lower or 'personal' in texto_lower:\n",
    "        return '1'\n",
    "    elif 'grupo' in texto_lower or 'equipo' in texto_lower:\n",
    "        return '2'\n",
    "    \n",
    "    return 'No especificado'\n",
    "\n",
    "def scrape_planinfantil_selenium():\n",
    "    \"\"\"\n",
    "    Función para hacer web scraping de la página https://www.planinfantil.es/planes/\n",
    "    utilizando Selenium para cargar contenido dinámico\n",
    "    \"\"\"\n",
    "    # URL de la página\n",
    "    url = \"https://www.planinfantil.es/planes/\"\n",
    "    \n",
    "    # Inicializamos el driver\n",
    "    driver = inicializar_driver()\n",
    "    if not driver:\n",
    "        print(\"No se pudo inicializar el driver de Selenium. ¿Está instalado Chrome?\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Abrimos la página\n",
    "        print(f\"Accediendo a {url}...\")\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Esperamos a que la página cargue completamente\n",
    "        time.sleep(5)  # Damos tiempo para que cargue el contenido dinámico\n",
    "        \n",
    "        # Imprimimos el título de la página para verificar que se cargó correctamente\n",
    "        print(f\"Título de la página: {driver.title}\")\n",
    "        \n",
    "        # Guardamos el HTML para análisis manual si es necesario\n",
    "        with open('pagina_selenium.html', 'w', encoding='utf-8') as f:\n",
    "            f.write(driver.page_source)\n",
    "        print(\"HTML guardado en 'pagina_selenium.html'\")\n",
    "        \n",
    "        # Analizamos la estructura de la página\n",
    "        print(\"Buscando eventos en la página...\")\n",
    "        \n",
    "        # Lista para almacenar la información de los eventos\n",
    "        eventos = []\n",
    "        \n",
    "        # Intentamos diferentes selectores para encontrar los eventos\n",
    "        selectores = [\n",
    "            'article', \n",
    "            '.elementor-posts-container article',\n",
    "            '.elementor-post',\n",
    "            '.elementor-posts article',\n",
    "            '.elementor-post__card',\n",
    "            '.elementor-grid article',\n",
    "            '.elementor-grid-item'\n",
    "        ]\n",
    "        \n",
    "        elementos_encontrados = False\n",
    "        \n",
    "        for selector in selectores:\n",
    "            try:\n",
    "                elementos = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                if elementos:\n",
    "                    print(f\"Se encontraron {len(elementos)} elementos con el selector '{selector}'\")\n",
    "                    elementos_encontrados = True\n",
    "                    \n",
    "                    for i, elemento in enumerate(elementos):\n",
    "                        try:\n",
    "                            # Intentamos extraer el título, puede estar en diferentes elementos\n",
    "                            titulo = None\n",
    "                            for selector_titulo in ['h3', 'h2', 'h1', '.elementor-post__title']:\n",
    "                                try:\n",
    "                                    titulo_elem = elemento.find_element(By.CSS_SELECTOR, selector_titulo)\n",
    "                                    titulo = titulo_elem.text.strip()\n",
    "                                    if titulo:\n",
    "                                        break\n",
    "                                except:\n",
    "                                    continue\n",
    "                            \n",
    "                            if not titulo:\n",
    "                                continue  # Si no encontramos un título, pasamos al siguiente elemento\n",
    "                            \n",
    "                            # Intentamos extraer la descripción, puede estar en diferentes elementos\n",
    "                            descripcion = \"No disponible\"\n",
    "                            for selector_desc in ['.elementor-post__excerpt', 'p', '.elementor-post__text']:\n",
    "                                try:\n",
    "                                    desc_elem = elemento.find_element(By.CSS_SELECTOR, selector_desc)\n",
    "                                    descripcion = desc_elem.text.strip()\n",
    "                                    if descripcion:\n",
    "                                        break\n",
    "                                except:\n",
    "                                    continue\n",
    "                            \n",
    "                            # Intentamos conseguir la URL del evento para visitarla luego\n",
    "                            url_evento = None\n",
    "                            try:\n",
    "                                link = elemento.find_element(By.TAG_NAME, 'a')\n",
    "                                url_evento = link.get_attribute('href')\n",
    "                            except:\n",
    "                                url_evento = None\n",
    "                            \n",
    "                            # Imprimimos para debug\n",
    "                            print(f\"Evento {i+1}: {titulo} - URL: {url_evento}\")\n",
    "                            \n",
    "                            # Generamos un ID único\n",
    "                            id_evento = str(uuid.uuid4())[:8]\n",
    "                            \n",
    "                            # Extraemos o inferimos el resto de la información\n",
    "                            texto_completo = f\"{titulo} {descripcion}\"\n",
    "                            \n",
    "                            # Categorización según el contenido\n",
    "                            categoria = categorizar_evento(titulo, descripcion)\n",
    "                            discapacidad = determinar_discapacidad(titulo, descripcion)\n",
    "                            costo = extraer_costo(texto_completo)\n",
    "                            edad_dirigida = determinar_edad(texto_completo)\n",
    "                            modalidad = determinar_modalidad(texto_completo)\n",
    "                            min_integrantes = determinar_min_integrantes(texto_completo)\n",
    "                            \n",
    "                            # Extraemos la ubicación o usamos valor por defecto\n",
    "                            ubicacion = \"Madrid\"  # Valor por defecto\n",
    "                            for selector_ubicacion in ['.elementor-post__meta-data', '.location', '.ubicacion']:\n",
    "                                try:\n",
    "                                    ubicacion_elem = elemento.find_element(By.CSS_SELECTOR, selector_ubicacion)\n",
    "                                    ubicacion = ubicacion_elem.text.strip()\n",
    "                                    break\n",
    "                                except:\n",
    "                                    continue\n",
    "                            \n",
    "                            # Si tenemos la URL del evento, visitamos la página para obtener más detalles\n",
    "                            if url_evento:\n",
    "                                try:\n",
    "                                    # Abrimos la página del evento en una nueva pestaña\n",
    "                                    driver.execute_script(f\"window.open('{url_evento}', '_blank');\")\n",
    "                                    driver.switch_to.window(driver.window_handles[1])\n",
    "                                    \n",
    "                                    # Esperamos a que cargue\n",
    "                                    time.sleep(3)\n",
    "                                    \n",
    "                                    # Obtenemos todo el texto de la página\n",
    "                                    texto_detallado = driver.find_element(By.TAG_NAME, 'body').text\n",
    "                                    \n",
    "                                    # Actualizamos datos con información más detallada\n",
    "                                    categoria = categorizar_evento(titulo, texto_detallado)\n",
    "                                    discapacidad = determinar_discapacidad(titulo, texto_detallado)\n",
    "                                    costo = extraer_costo(texto_detallado)\n",
    "                                    edad_dirigida = determinar_edad(texto_detallado)\n",
    "                                    modalidad = determinar_modalidad(texto_detallado)\n",
    "                                    min_integrantes = determinar_min_integrantes(texto_detallado)\n",
    "                                    \n",
    "                                    # Cerramos la pestaña y volvemos a la principal\n",
    "                                    driver.close()\n",
    "                                    driver.switch_to.window(driver.window_handles[0])\n",
    "                                except Exception as e:\n",
    "                                    print(f\"Error al obtener detalles de '{titulo}': {str(e)}\")\n",
    "                                    \n",
    "                                    # Aseguramos volver a la ventana principal si algo falla\n",
    "                                    if len(driver.window_handles) > 1:\n",
    "                                        driver.close()\n",
    "                                        driver.switch_to.window(driver.window_handles[0])\n",
    "                            \n",
    "                            # Guardamos los datos en un diccionario con la estructura requerida\n",
    "                            evento = {\n",
    "                                'id_evento': id_evento,\n",
    "                                'nombre_evento': titulo,\n",
    "                                'categoria': categoria,\n",
    "                                'discapacidad': discapacidad,\n",
    "                                'ubicacion': ubicacion,\n",
    "                                'costo': costo,\n",
    "                                'edad_dirigida': edad_dirigida,\n",
    "                                'min_integrantes': min_integrantes,\n",
    "                                'modalidad': modalidad\n",
    "                            }\n",
    "                            \n",
    "                            eventos.append(evento)\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"Error al procesar elemento {i+1}: {str(e)}\")\n",
    "                    \n",
    "                    # Si encontramos elementos con este selector, no seguimos probando\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(f\"Error con selector '{selector}': {str(e)}\")\n",
    "        \n",
    "        # Si no hemos encontrado eventos con los selectores anteriores, intentamos una aproximación más general\n",
    "        if not elementos_encontrados:\n",
    "            print(\"Intentando aproximación alternativa...\")\n",
    "            \n",
    "            # Obtenemos todos los enlaces de la página\n",
    "            enlaces = driver.find_elements(By.TAG_NAME, 'a')\n",
    "            \n",
    "            # Filtramos enlaces que parezcan ser de eventos\n",
    "            enlaces_eventos = []\n",
    "            for enlace in enlaces:\n",
    "                try:\n",
    "                    href = enlace.get_attribute('href')\n",
    "                    texto = enlace.text.strip()\n",
    "                    \n",
    "                    # Si el enlace tiene href, texto, y parece ser un evento (no una categoría o navegación)\n",
    "                    if href and texto and 'planinfantil.es/planes/' in href and not 'category' in href and not 'page' in href:\n",
    "                        enlaces_eventos.append((texto, href))\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            print(f\"Se encontraron {len(enlaces_eventos)} posibles enlaces a eventos\")\n",
    "            \n",
    "            # Procesamos cada enlace\n",
    "            for i, (titulo, url_evento) in enumerate(enlaces_eventos):\n",
    "                try:\n",
    "                    print(f\"Procesando evento {i+1}: {titulo}\")\n",
    "                    \n",
    "                    # Generamos un ID único\n",
    "                    id_evento = str(uuid.uuid4())[:8]\n",
    "                    \n",
    "                    # Valores por defecto\n",
    "                    descripcion = \"No disponible\"\n",
    "                    categoria = categorizar_evento(titulo, descripcion)\n",
    "                    discapacidad = \"Ninguna\"\n",
    "                    ubicacion = \"Madrid\"\n",
    "                    costo = \"No especificado\"\n",
    "                    edad_dirigida = \"No especificado\"\n",
    "                    min_integrantes = \"No especificado\"\n",
    "                    modalidad = \"No especificado\"\n",
    "                    \n",
    "                    # Visitamos la página del evento para obtener más detalles\n",
    "                    try:\n",
    "                        # Abrimos la página del evento\n",
    "                        driver.get(url_evento)\n",
    "                        time.sleep(3)\n",
    "                        \n",
    "                        # Obtenemos todo el texto de la página\n",
    "                        texto_detallado = driver.find_element(By.TAG_NAME, 'body').text\n",
    "                        \n",
    "                        # Actualizamos datos con información más detallada\n",
    "                        categoria = categorizar_evento(titulo, texto_detallado)\n",
    "                        discapacidad = determinar_discapacidad(titulo, texto_detallado)\n",
    "                        costo = extraer_costo(texto_detallado)\n",
    "                        edad_dirigida = determinar_edad(texto_detallado)\n",
    "                        modalidad = determinar_modalidad(texto_detallado)\n",
    "                        min_integrantes = determinar_min_integrantes(texto_detallado)\n",
    "                        \n",
    "                        # Intentamos encontrar la ubicación\n",
    "                        for palabra_clave in ['ubicación', 'dirección', 'lugar', 'se celebra en']:\n",
    "                            if palabra_clave in texto_detallado.lower():\n",
    "                                indice = texto_detallado.lower().find(palabra_clave)\n",
    "                                ubicacion_texto = texto_detallado[indice:indice+100]  # Tomamos 100 caracteres después\n",
    "                                ubicacion = ubicacion_texto.split('\\n')[0].strip()\n",
    "                                break\n",
    "                        \n",
    "                        # Volvemos a la página principal\n",
    "                        driver.get(url)\n",
    "                        time.sleep(2)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error al obtener detalles de '{titulo}': {str(e)}\")\n",
    "                        \n",
    "                        # Volvemos a la página principal\n",
    "                        driver.get(url)\n",
    "                        time.sleep(2)\n",
    "                    \n",
    "                    # Guardamos los datos en un diccionario con la estructura requerida\n",
    "                    evento = {\n",
    "                        'id_evento': id_evento,\n",
    "                        'nombre_evento': titulo,\n",
    "                        'categoria': categoria,\n",
    "                        'discapacidad': discapacidad,\n",
    "                        'ubicacion': ubicacion,\n",
    "                        'costo': costo,\n",
    "                        'edad_dirigida': edad_dirigida,\n",
    "                        'min_integrantes': min_integrantes,\n",
    "                        'modalidad': modalidad\n",
    "                    }\n",
    "                    \n",
    "                    eventos.append(evento)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error al procesar enlace {i+1}: {str(e)}\")\n",
    "        \n",
    "        # Creamos un DataFrame con la información estructurada\n",
    "        df = pd.DataFrame(eventos)\n",
    "        \n",
    "        if not df.empty:\n",
    "            # Eliminamos posibles duplicados\n",
    "            df = df.drop_duplicates(subset=['nombre_evento'])\n",
    "            \n",
    "            # Guardamos los datos en un archivo CSV\n",
    "            df.to_csv('planes_infantiles_selenium.csv', index=False, encoding='utf-8-sig')\n",
    "            \n",
    "            print(f\"Se han extraído y estructurado {len(df)} eventos y se han guardado en 'planes_infantiles_selenium.csv'\")\n",
    "        else:\n",
    "            print(\"No se encontraron eventos para extraer\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error general durante el scraping: {str(e)}\")\n",
    "        return None\n",
    "        \n",
    "    finally:\n",
    "        # Cerramos el driver\n",
    "        if driver:\n",
    "            driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Iniciando web scraping con Selenium...\")\n",
    "    df = scrape_planinfantil_selenium()\n",
    "    \n",
    "    if df is not None and not df.empty:\n",
    "        print(\"\\nPrimeros 5 eventos extraídos:\")\n",
    "        print(df.head())\n",
    "    else:\n",
    "        print(\"\\nNo se pudo extraer información de eventos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_evento</th>\n",
       "      <th>nombre_evento</th>\n",
       "      <th>categoria</th>\n",
       "      <th>discapacidad</th>\n",
       "      <th>ubicacion</th>\n",
       "      <th>costo</th>\n",
       "      <th>edad_dirigida</th>\n",
       "      <th>min_integrantes</th>\n",
       "      <th>modalidad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6bd28bb9</td>\n",
       "      <td>PARQUES</td>\n",
       "      <td>Talleres</td>\n",
       "      <td>Ninguna</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>No especificado</td>\n",
       "      <td>3-12 años</td>\n",
       "      <td>1</td>\n",
       "      <td>Exterior</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_evento nombre_evento categoria discapacidad ubicacion            costo  \\\n",
       "0  6bd28bb9       PARQUES  Talleres      Ninguna    Madrid  No especificado   \n",
       "\n",
       "  edad_dirigida min_integrantes modalidad  \n",
       "0     3-12 años               1  Exterior  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "def scrape_planinfantil_selenium():\n",
    "    \"\"\"\n",
    "    Función para hacer web scraping de la página https://www.planinfantil.es/planes/\n",
    "    utilizando Selenium para cargar contenido dinámico\n",
    "    \"\"\"\n",
    "    url = \"https://www.planinfantil.es/planes/\"\n",
    "    \n",
    "    # Inicializamos el driver\n",
    "    driver = inicializar_driver()\n",
    "    if not driver:\n",
    "        print(\"No se pudo inicializar el driver de Selenium.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Abrimos la página\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Esperamos a que los eventos estén presentes\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, '.elementor-posts-container article'))\n",
    "        )\n",
    "        \n",
    "        # Lista para almacenar los eventos\n",
    "        eventos_all = []\n",
    "        \n",
    "        # Extraemos eventos de la página actual\n",
    "        elementos = driver.find_elements(By.CSS_SELECTOR, '.elementor-posts-container article')\n",
    "        print(f\"Se encontraron {len(elementos)} eventos en esta página.\")\n",
    "        \n",
    "        # Procesamos cada evento\n",
    "        for i, elemento in enumerate(elementos):\n",
    "            # Aquí va el código para extraer título, descripción, etc.\n",
    "            pass\n",
    "        \n",
    "        # Intentamos obtener más páginas\n",
    "        while True:\n",
    "            try:\n",
    "                siguiente_pagina = driver.find_element(By.XPATH, '//a[@class=\"next\"]')\n",
    "                siguiente_pagina.click()\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_all_elements_located((By.CSS_SELECTOR, '.elementor-posts-container article'))\n",
    "                )\n",
    "                elementos = driver.find_elements(By.CSS_SELECTOR, '.elementor-posts-container article')\n",
    "                print(f\"Se encontraron {len(elementos)} eventos en esta página.\")\n",
    "                \n",
    "                # Procesamos los eventos de la nueva página\n",
    "                for i, elemento in enumerate(elementos):\n",
    "                    # Aquí va el código para extraer título, descripción, etc.\n",
    "                    pass\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(\"No hay más páginas para procesar.\")\n",
    "                break  # Salimos del bucle si no hay siguiente página\n",
    "        \n",
    "        # Creamos el DataFrame y guardamos los eventos\n",
    "        df = pd.DataFrame(eventos_all)\n",
    "        \n",
    "        if not df.empty:\n",
    "            df = df.drop_duplicates(subset=['nombre_evento'])\n",
    "            df.to_csv('planes_infantiles_selenium.csv', index=False, encoding='utf-8-sig')\n",
    "            print(f\"Se han extraído {len(df)} eventos.\")\n",
    "        else:\n",
    "            print(\"No se encontraron eventos para extraer\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error general durante el scraping: {str(e)}\")\n",
    "        return None\n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "def scrape_planinfantil_selenium():\n",
    "    \"\"\"\n",
    "    Función para hacer web scraping de la página https://www.planinfantil.es/planes/\n",
    "    utilizando Selenium para cargar contenido dinámico\n",
    "    \"\"\"\n",
    "    url = \"https://www.planinfantil.es/planes/\"\n",
    "    \n",
    "    # Inicializamos el driver\n",
    "    driver = inicializar_driver()\n",
    "    if not driver:\n",
    "        print(\"No se pudo inicializar el driver de Selenium.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Abrimos la página\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Esperamos a que los eventos estén presentes\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, '.elementor-posts-container article'))\n",
    "        )\n",
    "        \n",
    "        # Lista para almacenar los eventos\n",
    "        eventos_all = []\n",
    "        \n",
    "        # Extraemos eventos de la página actual\n",
    "        elementos = driver.find_elements(By.CSS_SELECTOR, '.elementor-posts-container article')\n",
    "        print(f\"Se encontraron {len(elementos)} eventos en esta página.\")\n",
    "        \n",
    "        # Procesamos cada evento\n",
    "        for i, elemento in enumerate(elementos):\n",
    "            # Aquí va el código para extraer título, descripción, etc.\n",
    "            pass\n",
    "        \n",
    "        # Intentamos obtener más páginas\n",
    "        while True:\n",
    "            try:\n",
    "                siguiente_pagina = driver.find_element(By.XPATH, '//a[@class=\"next\"]')\n",
    "                siguiente_pagina.click()\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_all_elements_located((By.CSS_SELECTOR, '.elementor-posts-container article'))\n",
    "                )\n",
    "                elementos = driver.find_elements(By.CSS_SELECTOR, '.elementor-posts-container article')\n",
    "                print(f\"Se encontraron {len(elementos)} eventos en esta página.\")\n",
    "                \n",
    "                # Procesamos los eventos de la nueva página\n",
    "                for i, elemento in enumerate(elementos):\n",
    "                    # Aquí va el código para extraer título, descripción, etc.\n",
    "                    pass\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(\"No hay más páginas para procesar.\")\n",
    "                break  # Salimos del bucle si no hay siguiente página\n",
    "        \n",
    "        # Creamos el DataFrame y guardamos los eventos\n",
    "        df = pd.DataFrame(eventos_all)\n",
    "        \n",
    "        if not df.empty:\n",
    "            df = df.drop_duplicates(subset=['nombre_evento'])\n",
    "            df.to_csv('planes_infantiles_selenium.csv', index=False, encoding='utf-8-sig')\n",
    "            print(f\"Se han extraído {len(df)} eventos.\")\n",
    "        else:\n",
    "            print(\"No se encontraron eventos para extraer\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error general durante el scraping: {str(e)}\")\n",
    "        return None\n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error general durante el scraping: Message: \n",
      "Stacktrace:\n",
      "0   chromedriver                        0x00000001059242c8 chromedriver + 6197960\n",
      "1   chromedriver                        0x000000010591b8ea chromedriver + 6162666\n",
      "2   chromedriver                        0x00000001053a0de0 chromedriver + 417248\n",
      "3   chromedriver                        0x00000001053f2797 chromedriver + 751511\n",
      "4   chromedriver                        0x00000001053f29b1 chromedriver + 752049\n",
      "5   chromedriver                        0x00000001054429b4 chromedriver + 1079732\n",
      "6   chromedriver                        0x00000001054189ed chromedriver + 907757\n",
      "7   chromedriver                        0x000000010543fcdb chromedriver + 1068251\n",
      "8   chromedriver                        0x0000000105418793 chromedriver + 907155\n",
      "9   chromedriver                        0x00000001053e4b25 chromedriver + 695077\n",
      "10  chromedriver                        0x00000001053e5791 chromedriver + 698257\n",
      "11  chromedriver                        0x00000001058e0cc0 chromedriver + 5921984\n",
      "12  chromedriver                        0x00000001058e4bb1 chromedriver + 5938097\n",
      "13  chromedriver                        0x00000001058bb004 chromedriver + 5767172\n",
      "14  chromedriver                        0x00000001058e55db chromedriver + 5940699\n",
      "15  chromedriver                        0x00000001058a9704 chromedriver + 5695236\n",
      "16  chromedriver                        0x00000001059090c8 chromedriver + 6086856\n",
      "17  chromedriver                        0x0000000105909290 chromedriver + 6087312\n",
      "18  chromedriver                        0x000000010591b4b1 chromedriver + 6161585\n",
      "19  libsystem_pthread.dylib             0x00007ff81858e18b _pthread_start + 99\n",
      "20  libsystem_pthread.dylib             0x00007ff818589ae3 thread_start + 15\n",
      "\n",
      "\n",
      "No se pudo extraer información de eventos\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import uuid\n",
    "import pandas as pd\n",
    "\n",
    "def inicializar_driver():\n",
    "    \"\"\"\n",
    "    Inicializa y configura el driver de Selenium\n",
    "    \"\"\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Ejecutar en modo headless (sin interfaz gráfica)\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    \n",
    "    try:\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "        return driver\n",
    "    except Exception as e:\n",
    "        print(f\"Error al inicializar el driver: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def scrape_planinfantil_selenium():\n",
    "    \"\"\"\n",
    "    Función para hacer web scraping de la página https://www.planinfantil.es/planes/\n",
    "    utilizando Selenium para cargar contenido dinámico\n",
    "    \"\"\"\n",
    "    driver = inicializar_driver()\n",
    "    if not driver:\n",
    "        print(\"No se pudo inicializar el driver de Selenium.\")\n",
    "        return None\n",
    "    \n",
    "    url = \"https://www.planinfantil.es/planes/\"\n",
    "    \n",
    "    try:\n",
    "        # Abrimos la página\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Esperamos a que la página cargue completamente\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, '.elementor-posts-container'))\n",
    "        )\n",
    "        \n",
    "        # Verificamos si la página se ha cargado correctamente\n",
    "        print(f\"Título de la página: {driver.title}\")\n",
    "        \n",
    "        # Intentamos extraer los elementos de la página\n",
    "        elementos = driver.find_elements(By.CSS_SELECTOR, '.elementor-posts-container article')\n",
    "        print(f\"Se encontraron {len(elementos)} eventos en esta página.\")\n",
    "        \n",
    "        eventos_all = []\n",
    "\n",
    "        # Procesamos los elementos\n",
    "        for i, elemento in enumerate(elementos):\n",
    "            try:\n",
    "                titulo = None\n",
    "                for selector_titulo in ['h3', 'h2', 'h1', '.elementor-post__title']:\n",
    "                    try:\n",
    "                        titulo_elem = elemento.find_element(By.CSS_SELECTOR, selector_titulo)\n",
    "                        titulo = titulo_elem.text.strip()\n",
    "                        if titulo:\n",
    "                            break\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error al extraer título: {str(e)}\")\n",
    "                \n",
    "                if not titulo:\n",
    "                    continue\n",
    "                \n",
    "                descripcion = \"No disponible\"\n",
    "                for selector_desc in ['.elementor-post__excerpt', 'p', '.elementor-post__text']:\n",
    "                    try:\n",
    "                        desc_elem = elemento.find_element(By.CSS_SELECTOR, selector_desc)\n",
    "                        descripcion = desc_elem.text.strip()\n",
    "                        if descripcion:\n",
    "                            break\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error al extraer descripción: {str(e)}\")\n",
    "                \n",
    "                url_evento = None\n",
    "                try:\n",
    "                    link = elemento.find_element(By.TAG_NAME, 'a')\n",
    "                    url_evento = link.get_attribute('href')\n",
    "                except Exception as e:\n",
    "                    print(f\"Error al obtener URL del evento: {str(e)}\")\n",
    "                \n",
    "                # Generamos un ID único para el evento\n",
    "                id_evento = str(uuid.uuid4())[:8]\n",
    "\n",
    "                evento = {\n",
    "                    'id_evento': id_evento,\n",
    "                    'nombre_evento': titulo,\n",
    "                    'categoria': 'No especificada',  # Puedes agregar la lógica para categorizar\n",
    "                    'discapacidad': 'Ninguna',  # Lógica para discapacidad\n",
    "                    'ubicacion': 'Madrid',  # Lógica para ubicación\n",
    "                    'costo': 'No especificado',  # Extraer el costo si es posible\n",
    "                    'edad_dirigida': 'No especificado',  # Lógica para edad dirigida\n",
    "                    'min_integrantes': 'No especificado',  # Lógica para determinar mínimo de integrantes\n",
    "                    'modalidad': 'No especificada',  # Lógica para modalidad\n",
    "                }\n",
    "\n",
    "                eventos_all.append(evento)\n",
    "            except Exception as e:\n",
    "                print(f\"Error al procesar el evento {i+1}: {str(e)}\")\n",
    "\n",
    "        # Convertimos los eventos en un DataFrame y lo guardamos en un archivo CSV\n",
    "        df = pd.DataFrame(eventos_all)\n",
    "\n",
    "        if not df.empty:\n",
    "            df = df.drop_duplicates(subset=['nombre_evento'])\n",
    "            df.to_csv('planes_infantiles_selenium.csv', index=False, encoding='utf-8-sig')\n",
    "            print(f\"Se han extraído {len(df)} eventos y se han guardado en 'planes_infantiles_selenium.csv'\")\n",
    "        else:\n",
    "            print(\"No se encontraron eventos para extraer\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        pridddfdfnt(f\"Error general durante el scraping: {str(e)}\")\n",
    "        return None\n",
    "    finally:\n",
    "dfddfffm miver:\n",
    "            di\n",
    "\n",
    "# Ejecutar la función de scraping\n",
    "if __name__ == \"__main__\":\n",
    "    df = scrape_planinfantil_selenium()\n",
    "    if df is not None and not df.empty:\n",
    "        print(\"\\nPrimeros 5 eventos extraídos:\")\n",
    "        print(df.head())\n",
    "    else:\n",
    "        print(\"\\nNo se pudo extraer información de eventos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planes con niños en Madrid - planinfantil.es\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Configurar opciones de Chrome\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Ejecutar sin interfaz gráfica si es necesario\n",
    "\n",
    "# Inicializar el driver con webdriver_manager (automáticamente gestionará la versión de ChromeDriver)\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "# Ahora puedes usar el driver para realizar scraping\n",
    "driver.get('https://www.planinfantil.es/planes/')  # Ejemplo de página\n",
    "\n",
    "# Realiza el scraping aquí...\n",
    "print(driver.title)\n",
    "\n",
    "# Cerrar el driver cuando termine\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "MaxRetryError",
     "evalue": "HTTPConnectionPool(host='localhost', port=50196): Max retries exceeded with url: /session/6f835628cfe62ccd3a5e2e87651603ef/elements (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x11e1ee450>: Failed to establish a new connection: [Errno 61] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectionRefusedError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS102024_/.venv/lib/python3.11/site-packages/urllib3/connection.py:198\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     sock = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS102024_/.venv/lib/python3.11/site-packages/urllib3/util/connection.py:85\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS102024_/.venv/lib/python3.11/site-packages/urllib3/util/connection.py:73\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     72\u001b[39m     sock.bind(source_address)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[31mConnectionRefusedError\u001b[39m: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mNewConnectionError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS102024_/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS102024_/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:493\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[32m    505\u001b[39m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[32m    506\u001b[39m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS102024_/.venv/lib/python3.11/site-packages/urllib3/connection.py:445\u001b[39m, in \u001b[36mHTTPConnection.request\u001b[39m\u001b[34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    444\u001b[39m     \u001b[38;5;28mself\u001b[39m.putheader(header, value)\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1289\u001b[39m, in \u001b[36mHTTPConnection.endheaders\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1288\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[32m-> \u001b[39m\u001b[32m1289\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1048\u001b[39m, in \u001b[36mHTTPConnection._send_output\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1047\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m-> \u001b[39m\u001b[32m1048\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1051\u001b[39m \n\u001b[32m   1052\u001b[39m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:986\u001b[39m, in \u001b[36mHTTPConnection.send\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    985\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_open:\n\u001b[32m--> \u001b[39m\u001b[32m986\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS102024_/.venv/lib/python3.11/site-packages/urllib3/connection.py:276\u001b[39m, in \u001b[36mHTTPConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    277\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tunnel_host:\n\u001b[32m    278\u001b[39m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS102024_/.venv/lib/python3.11/site-packages/urllib3/connection.py:213\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[32m    214\u001b[39m         \u001b[38;5;28mself\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    215\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    217\u001b[39m sys.audit(\u001b[33m\"\u001b[39m\u001b[33mhttp.client.connect\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m.port)\n",
      "\u001b[31mNewConnectionError\u001b[39m: <urllib3.connection.HTTPConnection object at 0x11e1ee450>: Failed to establish a new connection: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMaxRetryError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mselenium\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwebdriver\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msupport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m expected_conditions \u001b[38;5;28;01mas\u001b[39;00m EC\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Espera a que el contenedor de los artículos esté cargado\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mEC\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpresence_of_all_elements_located\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCSS_SELECTOR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m.elementor-posts-container article\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Extraemos los artículos de la página\u001b[39;00m\n\u001b[32m     11\u001b[39m elementos = driver.find_elements(By.CSS_SELECTOR, \u001b[33m'\u001b[39m\u001b[33m.elementor-posts-container article\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS102024_/.venv/lib/python3.11/site-packages/selenium/webdriver/support/wait.py:137\u001b[39m, in \u001b[36mWebDriverWait.until\u001b[39m\u001b[34m(self, method, message)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m         value = \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_driver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m value:\n\u001b[32m    139\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS102024_/.venv/lib/python3.11/site-packages/selenium/webdriver/support/expected_conditions.py:306\u001b[39m, in \u001b[36mpresence_of_all_elements_located.<locals>._predicate\u001b[39m\u001b[34m(driver)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_predicate\u001b[39m(driver: WebDriverOrWebElement):\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdriver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlocator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS102024_/.venv/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:936\u001b[39m, in \u001b[36mWebDriver.find_elements\u001b[39m\u001b[34m(self, by, value)\u001b[39m\n\u001b[32m    932\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.execute_script(find_element_js, by.to_dict())\n\u001b[32m    934\u001b[39m \u001b[38;5;66;03m# Return empty list if driver returns null\u001b[39;00m\n\u001b[32m    935\u001b[39m \u001b[38;5;66;03m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m936\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFIND_ELEMENTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43musing\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS102024_/.venv/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:427\u001b[39m, in \u001b[36mWebDriver.execute\u001b[39m\u001b[34m(self, driver_command, params)\u001b[39m\n\u001b[32m    424\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33msessionId\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m    425\u001b[39m         params[\u001b[33m\"\u001b[39m\u001b[33msessionId\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.session_id\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcommand_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[32m    429\u001b[39m     \u001b[38;5;28mself\u001b[39m.error_handler.check_response(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS102024_/.venv/lib/python3.11/site-packages/selenium/webdriver/remote/remote_connection.py:404\u001b[39m, in \u001b[36mRemoteConnection.execute\u001b[39m\u001b[34m(self, command, params)\u001b[39m\n\u001b[32m    402\u001b[39m trimmed = \u001b[38;5;28mself\u001b[39m._trim_large_entries(params)\n\u001b[32m    403\u001b[39m LOGGER.debug(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, command_info[\u001b[32m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS102024_/.venv/lib/python3.11/site-packages/selenium/webdriver/remote/remote_connection.py:428\u001b[39m, in \u001b[36mRemoteConnection._request\u001b[39m\u001b[34m(self, method, url, body)\u001b[39m\n\u001b[32m    425\u001b[39m     body = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client_config.keep_alive:\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    429\u001b[39m     statuscode = response.status\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS102024_/.venv/lib/python3.11/site-packages/urllib3/_request_methods.py:143\u001b[39m, in \u001b[36mRequestMethods.request\u001b[39m\u001b[34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[39m\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request_encode_url(\n\u001b[32m    136\u001b[39m         method,\n\u001b[32m    137\u001b[39m         url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    140\u001b[39m         **urlopen_kw,\n\u001b[32m    141\u001b[39m     )\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43murlopen_kw\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS102024_/.venv/lib/python3.11/site-packages/urllib3/_request_methods.py:278\u001b[39m, in \u001b[36mRequestMethods.request_encode_body\u001b[39m\u001b[34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[39m\n\u001b[32m    274\u001b[39m     extra_kw[\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m].setdefault(\u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m, content_type)\n\u001b[32m    276\u001b[39m extra_kw.update(urlopen_kw)\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS102024_/.venv/lib/python3.11/site-packages/urllib3/poolmanager.py:443\u001b[39m, in \u001b[36mPoolManager.urlopen\u001b[39m\u001b[34m(self, method, url, redirect, **kw)\u001b[39m\n\u001b[32m    441\u001b[39m     response = conn.urlopen(method, url, **kw)\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m redirect_location = redirect \u001b[38;5;129;01mand\u001b[39;00m response.get_redirect_location()\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS102024_/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:871\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    866\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[32m    867\u001b[39m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[32m    868\u001b[39m     log.warning(\n\u001b[32m    869\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) after connection broken by \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, retries, err, url\n\u001b[32m    870\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[32m    890\u001b[39m redirect_location = redirect \u001b[38;5;129;01mand\u001b[39;00m response.get_redirect_location()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS102024_/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:871\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    866\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[32m    867\u001b[39m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[32m    868\u001b[39m     log.warning(\n\u001b[32m    869\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) after connection broken by \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, retries, err, url\n\u001b[32m    870\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[32m    890\u001b[39m redirect_location = redirect \u001b[38;5;129;01mand\u001b[39;00m response.get_redirect_location()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS102024_/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:871\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    866\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[32m    867\u001b[39m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[32m    868\u001b[39m     log.warning(\n\u001b[32m    869\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) after connection broken by \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, retries, err, url\n\u001b[32m    870\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[32m    890\u001b[39m redirect_location = redirect \u001b[38;5;129;01mand\u001b[39;00m response.get_redirect_location()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS102024_/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    838\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_e, (\u001b[38;5;167;01mOSError\u001b[39;00m, HTTPException)):\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n\u001b[32m    846\u001b[39m \u001b[38;5;66;03m# Keep track of the error for the retry warning.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS102024_/.venv/lib/python3.11/site-packages/urllib3/util/retry.py:519\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m new_retry.is_exhausted():\n\u001b[32m    518\u001b[39m     reason = error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    521\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mIncremented Retry for (url=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, url, new_retry)\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m new_retry\n",
      "\u001b[31mMaxRetryError\u001b[39m: HTTPConnectionPool(host='localhost', port=50196): Max retries exceeded with url: /session/6f835628cfe62ccd3a5e2e87651603ef/elements (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x11e1ee450>: Failed to establish a new connection: [Errno 61] Connection refused'))"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Espera a que el contenedor de los artículos esté cargado\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_all_elements_located((By.CSS_SELECTOR, '.elementor-posts-container article'))\n",
    ")\n",
    "\n",
    "# Extraemos los artículos de la página\n",
    "elementos = driver.find_elements(By.CSS_SELECTOR, '.elementor-posts-container article')\n",
    "\n",
    "print(f\"Se encontraron {len(elementos)} eventos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutException",
     "evalue": "Message: \n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTimeoutException\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m driver.get(\u001b[33m\"\u001b[39m\u001b[33mhttps://www.planinfantil.es/planes/\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Esperar a que los artículos estén cargados\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mEC\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpresence_of_all_elements_located\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCSS_SELECTOR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m.elementor-posts-container article\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Extraer los eventos\u001b[39;00m\n\u001b[32m     25\u001b[39m elementos = driver.find_elements(By.CSS_SELECTOR, \u001b[33m'\u001b[39m\u001b[33m.elementor-posts-container article\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DS102024_/.venv/lib/python3.11/site-packages/selenium/webdriver/support/wait.py:146\u001b[39m, in \u001b[36mWebDriverWait.until\u001b[39m\u001b[34m(self, method, message)\u001b[39m\n\u001b[32m    144\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    145\u001b[39m     time.sleep(\u001b[38;5;28mself\u001b[39m._poll)\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[31mTimeoutException\u001b[39m: Message: \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Configurar opciones de Chrome\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Ejecutar sin interfaz gráfica si es necesario\n",
    "\n",
    "# Inicializar el driver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "# Acceder a la página\n",
    "driver.get(\"https://www.planinfantil.es/planes/\")\n",
    "\n",
    "# Esperar a que los artículos estén cargados\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_all_elements_located((By.CSS_SELECTOR, '.elementor-posts-container article'))\n",
    ")\n",
    "\n",
    "# Extraer los eventos\n",
    "elementos = driver.find_elements(By.CSS_SELECTOR, '.elementor-posts-container article')\n",
    "print(f\"Se encontraron {len(elementos)} eventos.\")\n",
    "\n",
    "# Imprimir el título de la página\n",
    "print(\"Título de la página:\", driver.title)\n",
    "\n",
    "# Cerrar el driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Título de la página: Planes con niños en Madrid - planinfantil.es\n",
      "Se encontraron 0 eventos.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL de la página de eventos\n",
    "url = 'https://www.planinfantil.es/planes/'\n",
    "\n",
    "# Realizamos la solicitud HTTP a la página\n",
    "response = requests.get(url)\n",
    "\n",
    "# Verificamos que la respuesta sea exitosa\n",
    "if response.status_code == 200:\n",
    "    # Parseamos el contenido de la página con BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Imprimimos el título de la página para verificar que hemos cargado correctamente\n",
    "    print(f\"Título de la página: {soup.title.string}\")\n",
    "    \n",
    "    # Buscar los elementos correctos (cambia el selector según la estructura)\n",
    "    eventos = soup.select('.panel-grid article')  # Usa el selector adecuado que encuentres en la página\n",
    "\n",
    "    # Verificamos cuántos eventos hemos encontrado\n",
    "    print(f\"Se encontraron {len(eventos)} eventos.\")\n",
    "    \n",
    "    # Extraer detalles de los eventos\n",
    "    for i, evento in enumerate(eventos):\n",
    "        try:\n",
    "            # Extraemos el título del evento\n",
    "            titulo = evento.find('h2').text.strip() if evento.find('h2') else 'Sin título'\n",
    "            \n",
    "            # Extraemos la descripción del evento (ajusta según lo que encuentres en el HTML)\n",
    "            descripcion = evento.find('p').text.strip() if evento.find('p') else 'Sin descripción'\n",
    "            \n",
    "            # Imprimir los resultados\n",
    "            print(f\"Evento {i + 1}:\")\n",
    "            print(f\"Título: {titulo}\")\n",
    "            print(f\"Descripción: {descripcion}\")\n",
    "            print(\"-\" * 50)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error al procesar el evento {i + 1}: {str(e)}\")\n",
    "else:\n",
    "    print(f\"Error al acceder a la página. Código de estado: {response.status_code}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
