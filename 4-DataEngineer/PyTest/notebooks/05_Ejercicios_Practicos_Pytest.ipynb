{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios Prácticos de Pytest para Data Engineering\n",
    "\n",
    "En este notebook, encontrarás una serie de ejercicios prácticos para aplicar lo que has aprendido sobre pytest en el contexto de Data Engineering. Estos ejercicios están diseñados para reforzar los conceptos y técnicas presentados en los notebooks anteriores.\n",
    "\n",
    "Utilizaremos el dataset de ventas de productos que hemos estado usando a lo largo del tutorial. Cada ejercicio incluye instrucciones detalladas y, en algunos casos, código inicial para ayudarte a comenzar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración Inicial\n",
    "\n",
    "Primero, vamos a importar las bibliotecas necesarias y cargar nuestro dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fecha</th>\n",
       "      <th>producto</th>\n",
       "      <th>categoria</th>\n",
       "      <th>precio</th>\n",
       "      <th>cantidad</th>\n",
       "      <th>descuento</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>Laptop HP</td>\n",
       "      <td>Electrónica</td>\n",
       "      <td>899.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>854.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>Monitor Dell</td>\n",
       "      <td>Electrónica</td>\n",
       "      <td>249.99</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>499.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>Teclado Logitech</td>\n",
       "      <td>Accesorios</td>\n",
       "      <td>59.99</td>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>161.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>Mouse Inalámbrico</td>\n",
       "      <td>Accesorios</td>\n",
       "      <td>29.99</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>149.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2023-01-25</td>\n",
       "      <td>Disco SSD 500GB</td>\n",
       "      <td>Almacenamiento</td>\n",
       "      <td>89.99</td>\n",
       "      <td>2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>152.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       fecha           producto       categoria  precio  cantidad  \\\n",
       "0   1  2023-01-05          Laptop HP     Electrónica  899.99         1   \n",
       "1   2  2023-01-10       Monitor Dell     Electrónica  249.99         2   \n",
       "2   3  2023-01-15   Teclado Logitech      Accesorios   59.99         3   \n",
       "3   4  2023-01-20  Mouse Inalámbrico      Accesorios   29.99         5   \n",
       "4   5  2023-01-25    Disco SSD 500GB  Almacenamiento   89.99         2   \n",
       "\n",
       "   descuento   total  \n",
       "0       0.05  854.99  \n",
       "1       0.00  499.98  \n",
       "2       0.10  161.97  \n",
       "3       0.00  149.95  \n",
       "4       0.15  152.98  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytest\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Añadimos el directorio raíz al path para poder importar los módulos\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Cargamos el dataset\n",
    "df_ventas = pd.read_csv('../data/ventas_productos.csv')\n",
    "\n",
    "# Mostramos las primeras filas\n",
    "df_ventas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Testing de una Función de Análisis de Rentabilidad\n",
    "\n",
    "### Descripción\n",
    "\n",
    "En este ejercicio, implementarás una función que calcule la rentabilidad de cada producto en el dataset de ventas y escribirás tests para verificar su correcto funcionamiento.\n",
    "\n",
    "La rentabilidad se define como: `(precio * cantidad * (1 - descuento)) / (precio * cantidad) * 100`\n",
    "\n",
    "Es decir, el porcentaje del ingreso potencial que realmente se obtuvo después de aplicar descuentos.\n",
    "\n",
    "### Tarea 1: Implementa la función `calcular_rentabilidad`\n",
    "\n",
    "Completa la siguiente función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_rentabilidad(df):\n",
    "    \"\"\"Calcula la rentabilidad de cada producto en el dataset de ventas.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con columnas 'precio', 'cantidad', 'descuento' y 'total'\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame original con una columna adicional 'rentabilidad' (en porcentaje)\n",
    "    \"\"\"\n",
    "    # Tu código aquí\n",
    "    # Recuerda: rentabilidad = (precio * cantidad * (1 - descuento)) / (precio * cantidad) * 100\n",
    "    \n",
    "    # Sugerencia: Crea una copia del DataFrame para no modificar el original\n",
    "    df_resultado = df.copy()\n",
    "    \n",
    "    # Calcula la rentabilidad\n",
    "    # ...\n",
    "    \n",
    "    return df_resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_rentabilidad(df):\n",
    "    \n",
    "    # Crear una copia del DataFrame original\n",
    "    df_resultado = df.copy()\n",
    "    \n",
    "    # Calcular el ingreso potencial (sin descuento)\n",
    "    ingreso_potencial = df_resultado['precio'] * df_resultado['cantidad']\n",
    "    \n",
    "    # Calcular el ingreso real (con descuento)\n",
    "    ingreso_real = ingreso_potencial * (1 - df_resultado['descuento'])\n",
    "    \n",
    "    # Calcular la rentabilidad en porcentaje\n",
    "    df_resultado['rentabilidad'] = (ingreso_real / ingreso_potencial) * 100\n",
    "\n",
    "    return df_resultado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2: Escribe tests para la función `calcular_rentabilidad`\n",
    "\n",
    "Escribe al menos tres tests para verificar que la función `calcular_rentabilidad` funcione correctamente. Deberías verificar:\n",
    "\n",
    "1. Que la función añada la columna 'rentabilidad' al DataFrame\n",
    "2. Que los valores de rentabilidad sean correctos para algunos casos específicos\n",
    "3. Que la función maneje correctamente casos especiales (por ejemplo, descuento = 0)\n",
    "\n",
    "Completa el siguiente archivo de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test_rentabilidad.py\n"
     ]
    }
   ],
   "source": [
    "%%file test_rentabilidad.py\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calcular_rentabilidad(df):\n",
    "    \"\"\"Calcula la rentabilidad de cada producto en el dataset de ventas.\"\"\"\n",
    "    df_resultado = df.copy()\n",
    "    df_resultado['rentabilidad'] = (1 - df_resultado['descuento']) * 100\n",
    "    return df_resultado\n",
    "\n",
    "@pytest.fixture\n",
    "def df_test():\n",
    "    \"\"\"Fixture que crea un DataFrame de prueba.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'producto': ['Producto A', 'Producto B', 'Producto C'],\n",
    "        'precio': [100.0, 200.0, 300.0],\n",
    "        'cantidad': [2, 1, 3],\n",
    "        'descuento': [0.1, 0.0, 0.25],\n",
    "        'total': [180.0, 200.0, 675.0]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def test_columna_rentabilidad_existe(df_test):\n",
    "    resultado = calcular_rentabilidad(df_test)\n",
    "    assert 'rentabilidad' in resultado.columns, \"La columna 'rentabilidad' no fue añadida\"\n",
    "\n",
    "def test_valores_rentabilidad_correctos(df_test):\n",
    "    resultado = calcular_rentabilidad(df_test)\n",
    "    valores_esperados = [90.0, 100.0, 75.0]  # (1 - descuento) * 100\n",
    "    np.testing.assert_allclose(resultado['rentabilidad'], valores_esperados, rtol=1e-2) #Compara que los valores reales de resultado['rentabilidad'] estén muy cerca (con tolerancia relativa del 1%) de los valores esperados\n",
    "\n",
    "def test_caso_descuento_cero(df_test):\n",
    "    resultado = calcular_rentabilidad(df_test)\n",
    "    rentabilidad_producto_b = resultado.loc[resultado['producto'] == 'Producto B', 'rentabilidad'].values[0] # Filtra solo el producto \"Producto B\", obtiene el valor de su rentabilidad.\n",
    "    assert rentabilidad_producto_b == 100.0, \"Rentabilidad debería ser 100% cuando el descuento es 0\" #Verifica que ese valor sea exactamente 100%, como se espera si no se aplicó ningún descuento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "poetry run pytest test_rentabilidad.py esto en consola"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 3: Ejecuta los tests\n",
    "\n",
    "Ejecuta los tests que has escrito para verificar que la función `calcular_rentabilidad` funcione correctamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.7, pytest-8.3.5, pluggy-1.5.0 -- /Users/isaromobru/Desktop/DS102024_/.venv/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/isaromobru/Desktop/DS102024_\n",
      "configfile: pyproject.toml\n",
      "plugins: anyio-4.8.0, cov-6.1.0\n",
      "collected 3 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "test_rentabilidad.py::test_columna_rentabilidad_existe \u001b[32mPASSED\u001b[0m\n",
      "test_rentabilidad.py::test_valores_rentabilidad_correctos \u001b[32mPASSED\u001b[0m\n",
      "test_rentabilidad.py::test_caso_descuento_cero \u001b[32mPASSED\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 2.05s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Ejecuta los tests\n",
    "!pytest -xvs test_rentabilidad.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Testing de una Función de Detección de Anomalías\n",
    "\n",
    "### Descripción\n",
    "\n",
    "En este ejercicio, implementarás una función que detecte anomalías en el dataset de ventas y escribirás tests para verificar su correcto funcionamiento.\n",
    "\n",
    "Una anomalía se define como un valor que está más de 2 desviaciones estándar por encima o por debajo de la media de una columna numérica.\n",
    "\n",
    "### Tarea 1: Implementa la función `detectar_anomalias`\n",
    "\n",
    "Completa la siguiente función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_anomalias(df, columna, umbral=2.0):\n",
    "    \"\"\"Detecta anomalías en una columna numérica del DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con la columna a analizar\n",
    "        columna: Nombre de la columna numérica a analizar\n",
    "        umbral: Número de desviaciones estándar para considerar un valor como anomalía\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame con las filas que contienen anomalías\n",
    "    \"\"\"\n",
    "    # Crear una copia del DataFrame para no modificar el original\n",
    "    df_resultado = df.copy()\n",
    "    \n",
    "    # Calcular la media y desviación estándar de la columna\n",
    "    media = df_resultado[columna].mean()\n",
    "    desviacion = df_resultado[columna].std()\n",
    "    \n",
    "    # Definir los límites superior e inferior para anomalías\n",
    "    limite_superior = media + umbral * desviacion\n",
    "    limite_inferior = media - umbral * desviacion\n",
    "    \n",
    "    # Filtrar las filas que están fuera de los límites\n",
    "    df_anomalias = df_resultado[\n",
    "        (df_resultado[columna] > limite_superior) |\n",
    "        (df_resultado[columna] < limite_inferior)\n",
    "    ]\n",
    "    \n",
    "    return df_anomalias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2: Escribe tests para la función `detectar_anomalias`\n",
    "\n",
    "Escribe al menos tres tests para verificar que la función `detectar_anomalias` funcione correctamente. Deberías verificar:\n",
    "\n",
    "1. Que la función detecte correctamente anomalías por encima de la media\n",
    "2. Que la función detecte correctamente anomalías por debajo de la media\n",
    "3. Que la función maneje correctamente diferentes valores de umbral\n",
    "\n",
    "Completa el siguiente archivo de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_anomalias.py\n"
     ]
    }
   ],
   "source": [
    "%%file test_anomalias.py\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def detectar_anomalias(df, columna, umbral=2.0):\n",
    "    \"\"\"Detecta anomalías en una columna numérica del DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con la columna a analizar\n",
    "        columna: Nombre de la columna numérica a analizar\n",
    "        umbral: Número de desviaciones estándar para considerar un valor como anomalía\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame con las filas que contienen anomalías\n",
    "    \"\"\"\n",
    "    # Crear una copia del DataFrame para no modificar el original\n",
    "    df_resultado = df.copy()\n",
    "    \n",
    "    # Calcular la media y desviación estándar de la columna\n",
    "    media = df_resultado[columna].mean()\n",
    "    desviacion = df_resultado[columna].std()\n",
    "    \n",
    "    # Definir los límites superior e inferior para anomalías\n",
    "    limite_superior = media + umbral * desviacion\n",
    "    limite_inferior = media - umbral * desviacion\n",
    "    \n",
    "    # Filtrar las filas que están fuera de los límites\n",
    "    df_anomalias = df_resultado[\n",
    "        (df_resultado[columna] > limite_superior) |\n",
    "        (df_resultado[columna] < limite_inferior)\n",
    "    ]\n",
    "    \n",
    "    return df_anomalias\n",
    "\n",
    "@pytest.fixture\n",
    "def df_test():\n",
    "    \"\"\"Fixture que crea un DataFrame de prueba con valores normales y anómalos.\"\"\"\n",
    "    # Crea un DataFrame con valores normales (alrededor de 100) y algunos valores anómalos\n",
    "    np.random.seed(42)  # Para reproducibilidad\n",
    "    valores_normales = np.random.normal(100, 10, 20)  # 20 valores normales con media 100 y desv. std. 10\n",
    "    valores_anomalos_altos = [150, 160]  # Anomalías por encima (> media + 2*desv_std = 100 + 2*10 = 120)\n",
    "    valores_anomalos_bajos = [60, 50]  # Anomalías por debajo (< media - 2*desv_std = 100 - 2*10 = 80)\n",
    "    \n",
    "    valores = np.concatenate([valores_normales, valores_anomalos_altos, valores_anomalos_bajos])\n",
    "    ids = range(1, len(valores) + 1)\n",
    "    \n",
    "    return pd.DataFrame({'id': ids, 'valor': valores})\n",
    "def test_detecta_anomalias_por_encima(df_test):\n",
    "    resultado = detectar_anomalias(df_test, 'valor', umbral=2.0)\n",
    "    valores_anomalos = resultado['valor'].values\n",
    "    # Comprobamos que los valores altos (150, 160) están en los resultados\n",
    "    assert any(v in valores_anomalos for v in [150, 160]), \"No se detectaron las anomalías altas esperadas\"\n",
    "    # Aseguramos que el resto no fue incluido por error\n",
    "    assert all(v >= 120 or v <= 80 for v in valores_anomalos)\n",
    "\n",
    "def test_detecta_anomalias_por_debajo(df_test):\n",
    "    resultado = detectar_anomalias(df_test, 'valor', umbral=2.0)\n",
    "    valores_anomalos = resultado['valor'].values\n",
    "    # Comprobamos que los valores bajos (60, 50) están en los resultados\n",
    "    assert any(v in valores_anomalos for v in [60, 50]), \"No se detectaron las anomalías bajas esperadas\"\n",
    "    # Aseguramos que el resto no fue incluido por error\n",
    "    assert all(v >= 120 or v <= 80 for v in valores_anomalos)\n",
    "\n",
    "def test_umbral_diferente(df_test):\n",
    "    resultado = detectar_anomalias(df_test, 'valor', umbral=3.0)\n",
    "    # Con umbral 3.0, ninguna observación debería estar fuera si std=10 → límites: 70–130\n",
    "    # 150 y 160 todavía deberían ser detectadas, pero quizá 60 y 50 no si la std es mayor por outliers\n",
    "    # Entonces, verificamos que haya menos anomalías que con umbral=2.0\n",
    "    resultado_2 = detectar_anomalias(df_test, 'valor', umbral=2.0)\n",
    "    assert len(resultado) <= len(resultado_2), \"Con umbral mayor debería haber igual o menos anomalías\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 3: Ejecuta los tests\n",
    "\n",
    "Ejecuta los tests que has escrito para verificar que la función `detectar_anomalias` funcione correctamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.7, pytest-8.3.5, pluggy-1.5.0 -- /Users/isaromobru/Desktop/DS102024_/.venv/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/isaromobru/Desktop/DS102024_\n",
      "configfile: pyproject.toml\n",
      "plugins: anyio-4.8.0, cov-6.1.0\n",
      "collected 3 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "test_anomalias.py::test_detecta_anomalias_por_encima \u001b[32mPASSED\u001b[0m\n",
      "test_anomalias.py::test_detecta_anomalias_por_debajo \u001b[32mPASSED\u001b[0m\n",
      "test_anomalias.py::test_umbral_diferente \u001b[32mPASSED\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 2.09s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Ejecuta los tests\n",
    "!pytest -xvs test_anomalias.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Testing de una Función de Segmentación de Clientes\n",
    "\n",
    "### Descripción\n",
    "\n",
    "En este ejercicio, implementarás una función que segmente los productos en el dataset de ventas según su precio y popularidad, y escribirás tests para verificar su correcto funcionamiento.\n",
    "\n",
    "### Tarea 1: Implementa la función `segmentar_productos`\n",
    "\n",
    "Completa la siguiente función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentar_productos(df):\n",
    "    \"\"\"Segmenta los productos según su precio y popularidad (cantidad vendida).\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con columnas 'producto', 'precio' y 'cantidad'\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame con los productos segmentados\n",
    "    \"\"\"\n",
    "    # Agrupar por producto y precio promedio, y sumar la cantidad vendida\n",
    "    resumen = df.groupby('producto').agg({\n",
    "        'precio': 'mean',\n",
    "        'cantidad': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Segmentación por precio\n",
    "    def clasificar_precio(precio):\n",
    "        if precio < 50:\n",
    "            return 'Económico'\n",
    "        elif 50 <= precio < 100:\n",
    "            return 'Estándar'\n",
    "        elif 100 <= precio < 200:\n",
    "            return 'Premium'\n",
    "        else:\n",
    "            return 'Lujo'\n",
    "    \n",
    "    # Segmentación por popularidad\n",
    "    def clasificar_popularidad(cantidad):\n",
    "        if cantidad < 2:\n",
    "            return 'Baja'\n",
    "        elif 2 <= cantidad < 4:\n",
    "            return 'Media'\n",
    "        else:\n",
    "            return 'Alta'\n",
    "    \n",
    "    resumen['segmento_precio'] = resumen['precio'].apply(clasificar_precio)\n",
    "    resumen['segmento_popularidad'] = resumen['cantidad'].apply(clasificar_popularidad)\n",
    "    \n",
    "    return resumen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2: Escribe tests para la función `segmentar_productos`\n",
    "\n",
    "Escribe al menos tres tests para verificar que la función `segmentar_productos` funcione correctamente. Deberías verificar:\n",
    "\n",
    "1. Que la función segmente correctamente por precio\n",
    "2. Que la función segmente correctamente por popularidad\n",
    "3. Que la función maneje correctamente productos con múltiples ventas\n",
    "\n",
    "Completa el siguiente archivo de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test_segmentacion.py\n"
     ]
    }
   ],
   "source": [
    "%%file test_segmentacion.py\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def segmentar_productos(df):\n",
    "    \"\"\"Segmenta los productos según su precio y popularidad (cantidad vendida).\"\"\"\n",
    "    # Agrupa por producto y calcula el precio promedio y la cantidad total\n",
    "    df_agrupado = df.groupby('producto').agg({\n",
    "        'precio': 'mean',\n",
    "        'cantidad': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Segmentación por precio\n",
    "    condiciones_precio = [\n",
    "        (df_agrupado['precio'] < 50),\n",
    "        (df_agrupado['precio'] >= 50) & (df_agrupado['precio'] < 100),\n",
    "        (df_agrupado['precio'] >= 100) & (df_agrupado['precio'] < 200),\n",
    "        (df_agrupado['precio'] >= 200)\n",
    "    ]\n",
    "    categorias_precio = ['Económico', 'Estándar', 'Premium', 'Lujo']\n",
    "    df_agrupado['segmento_precio'] = np.select(condiciones_precio, categorias_precio, default='Sin categoría')\n",
    "    \n",
    "    # Segmentación por popularidad\n",
    "    condiciones_popularidad = [\n",
    "        (df_agrupado['cantidad'] < 2),\n",
    "        (df_agrupado['cantidad'] >= 2) & (df_agrupado['cantidad'] < 4),\n",
    "        (df_agrupado['cantidad'] >= 4)\n",
    "    ]\n",
    "    categorias_popularidad = ['Baja', 'Media', 'Alta']\n",
    "    df_agrupado['segmento_popularidad'] = np.select(condiciones_popularidad, categorias_popularidad, default='Sin categoría')\n",
    "    \n",
    "    return df_agrupado\n",
    "\n",
    "@pytest.fixture\n",
    "def df_test():\n",
    "    \"\"\"Fixture que crea un DataFrame de prueba con diferentes productos.\"\"\"\n",
    "    data = {\n",
    "        'producto': ['Producto A', 'Producto A', 'Producto B', 'Producto C', 'Producto D', 'Producto E'],\n",
    "        'precio': [30.0, 30.0, 75.0, 150.0, 250.0, 50.0],\n",
    "        'cantidad': [1, 2, 2, 3, 1, 5]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Escribe tus tests aquí\n",
    "def test_segmentacion_por_precio(df_test):\n",
    "    resultado = segmentar_productos(df_test)\n",
    "    segmentos = dict(zip(resultado['producto'], resultado['segmento_precio']))\n",
    "    \n",
    "    assert segmentos['Producto A'] == 'Económico'    # Precio: 30\n",
    "    assert segmentos['Producto B'] == 'Estándar'     # Precio: 75\n",
    "    assert segmentos['Producto C'] == 'Premium'      # Precio: 150\n",
    "    assert segmentos['Producto D'] == 'Lujo'         # Precio: 250\n",
    "    assert segmentos['Producto E'] == 'Estándar'     # Precio: 50\n",
    "\n",
    "def test_segmentacion_por_popularidad(df_test):\n",
    "    resultado = segmentar_productos(df_test)\n",
    "    popularidades = dict(zip(resultado['producto'], resultado['segmento_popularidad']))\n",
    "    \n",
    "    assert popularidades['Producto A'] == 'Media'    # Cantidad: 1 + 2 = 3\n",
    "    assert popularidades['Producto B'] == 'Media'    # Cantidad: 2\n",
    "    assert popularidades['Producto C'] == 'Media'    # Cantidad: 3\n",
    "    assert popularidades['Producto D'] == 'Baja'     # Cantidad: 1\n",
    "    assert popularidades['Producto E'] == 'Alta'     # Cantidad: 5\n",
    "\n",
    "def test_productos_multiples_ventas(df_test):\n",
    "    resultado = segmentar_productos(df_test)\n",
    "    producto_a = resultado[resultado['producto'] == 'Producto A']\n",
    "    \n",
    "    assert producto_a['precio'].values[0] == 30.0              # Promedio entre 30 y 30\n",
    "    assert producto_a['cantidad'].values[0] == 3               # 1 + 2\n",
    "    assert producto_a['segmento_precio'].values[0] == 'Económico'\n",
    "    assert producto_a['segmento_popularidad'].values[0] == 'Media'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 3: Ejecuta los tests\n",
    "\n",
    "Ejecuta los tests que has escrito para verificar que la función `segmentar_productos` funcione correctamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.7, pytest-8.3.5, pluggy-1.5.0 -- /Users/isaromobru/Desktop/DS102024_/.venv/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/isaromobru/Desktop/DS102024_\n",
      "configfile: pyproject.toml\n",
      "plugins: anyio-4.8.0, cov-6.1.0\n",
      "collected 3 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "test_segmentacion.py::test_segmentacion_por_precio \u001b[32mPASSED\u001b[0m\n",
      "test_segmentacion.py::test_segmentacion_por_popularidad \u001b[32mPASSED\u001b[0m\n",
      "test_segmentacion.py::test_productos_multiples_ventas \u001b[32mPASSED\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 2.06s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Ejecuta los tests\n",
    "!pytest -xvs test_segmentacion.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: Testing de un Pipeline de Preprocesamiento\n",
    "\n",
    "### Descripción\n",
    "\n",
    "En este ejercicio, implementarás un pipeline de preprocesamiento para el dataset de ventas y escribirás tests para verificar su correcto funcionamiento.\n",
    "\n",
    "### Tarea 1: Implementa la clase `PipelinePreprocesamiento`\n",
    "\n",
    "Completa la siguiente clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class PipelinePreprocesamiento:\n",
    "    \"\"\"Pipeline de preprocesamiento para el dataset de ventas.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Inicializa el pipeline.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def convertir_tipos(self, df):\n",
    "        \"\"\"Convierte las columnas a los tipos de datos correctos.\"\"\"\n",
    "        df_convertido = df.copy()\n",
    "\n",
    "        # Convertir columnas al tipo correspondiente\n",
    "        df_convertido['fecha'] = pd.to_datetime(df_convertido['fecha'], errors='coerce')\n",
    "        df_convertido['precio'] = df_convertido['precio'].astype(float)\n",
    "        df_convertido['descuento'] = df_convertido['descuento'].astype(float)\n",
    "        df_convertido['total'] = df_convertido['total'].astype(float)\n",
    "        df_convertido['cantidad'] = df_convertido['cantidad'].astype(int)\n",
    "\n",
    "        return df_convertido\n",
    "\n",
    "    def eliminar_duplicados(self, df):\n",
    "        \"\"\"Elimina filas duplicadas del DataFrame.\"\"\"\n",
    "        df_sin_duplicados = df.drop_duplicates()\n",
    "        return df_sin_duplicados\n",
    "\n",
    "    def normalizar_categorias(self, df):\n",
    "        \"\"\"Normaliza las categorías (primera letra mayúscula, resto minúsculas).\"\"\"\n",
    "        df_normalizado = df.copy()\n",
    "        if 'categoria' in df_normalizado.columns:\n",
    "            df_normalizado['categoria'] = df_normalizado['categoria'].str.capitalize()\n",
    "        return df_normalizado\n",
    "\n",
    "    def procesar(self, df):\n",
    "        \"\"\"Aplica todo el pipeline de preprocesamiento.\"\"\"\n",
    "        df_procesado = self.convertir_tipos(df)\n",
    "        df_procesado = self.eliminar_duplicados(df_procesado)\n",
    "        df_procesado = self.normalizar_categorias(df_procesado)\n",
    "        return df_procesado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2: Escribe tests para la clase `PipelinePreprocesamiento`\n",
    "\n",
    "Escribe tests para verificar que cada método de la clase `PipelinePreprocesamiento` funcione correctamente. Deberías verificar:\n",
    "\n",
    "1. Que `convertir_tipos` convierta correctamente los tipos de datos\n",
    "2. Que `eliminar_duplicados` elimine correctamente las filas duplicadas\n",
    "3. Que `normalizar_categorias` normalice correctamente las categorías\n",
    "4. Que `procesar` aplique correctamente todas las transformaciones\n",
    "\n",
    "Completa el siguiente archivo de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test_pipeline_preprocesamiento.py\n"
     ]
    }
   ],
   "source": [
    "%%file test_pipeline_preprocesamiento.py\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class PipelinePreprocesamiento:\n",
    "    \"\"\"Pipeline de preprocesamiento para el dataset de ventas.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Inicializa el pipeline.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def convertir_tipos(self, df):\n",
    "        \"\"\"Convierte las columnas a los tipos de datos correctos.\"\"\"\n",
    "        df_convertido = df.copy()\n",
    "        df_convertido['fecha'] = pd.to_datetime(df_convertido['fecha'])\n",
    "        df_convertido['precio'] = pd.to_numeric(df_convertido['precio'])\n",
    "        df_convertido['cantidad'] = pd.to_numeric(df_convertido['cantidad']).astype(int)\n",
    "        df_convertido['descuento'] = pd.to_numeric(df_convertido['descuento'])\n",
    "        df_convertido['total'] = pd.to_numeric(df_convertido['total'])\n",
    "        return df_convertido\n",
    "    \n",
    "    def eliminar_duplicados(self, df):\n",
    "        \"\"\"Elimina filas duplicadas del DataFrame.\"\"\"\n",
    "        return df.drop_duplicates()\n",
    "    \n",
    "    def normalizar_categorias(self, df):\n",
    "        \"\"\"Normaliza las categorías (primera letra mayúscula, resto minúsculas).\"\"\"\n",
    "        df_normalizado = df.copy()\n",
    "        df_normalizado['categoria'] = df_normalizado['categoria'].str.capitalize()\n",
    "        return df_normalizado\n",
    "    \n",
    "    def procesar(self, df):\n",
    "        \"\"\"Aplica todo el pipeline de preprocesamiento.\"\"\"\n",
    "        df_procesado = df.copy()\n",
    "        df_procesado = self.convertir_tipos(df_procesado)\n",
    "        df_procesado = self.eliminar_duplicados(df_procesado)\n",
    "        df_procesado = self.normalizar_categorias(df_procesado)\n",
    "        return df_procesado\n",
    "\n",
    "@pytest.fixture\n",
    "def df_test():\n",
    "    \"\"\"Fixture que crea un DataFrame de prueba con problemas para preprocesar.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3, 3],  # ID duplicado\n",
    "        'fecha': ['2023-01-05', '2023-01-10', '2023-01-15', '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech', 'Teclado Logitech'],\n",
    "        'categoria': ['ELECTRÓNICA', 'electrónica', 'Accesorios', 'accesorios'],  # Inconsistencia en mayúsculas/minúsculas\n",
    "        'precio': ['899.99', '249.99', '59.99', '59.99'],  # Strings en lugar de float\n",
    "        'cantidad': ['1', '2', '3', '3'],  # Strings en lugar de int\n",
    "        'descuento': [0.05, 0.00, 0.10, 0.10],\n",
    "        'total': [854.99, 499.98, 161.97, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def test_convertir_tipos(df_test):\n",
    "    pipeline = PipelinePreprocesamiento()\n",
    "    df_convertido = pipeline.convertir_tipos(df_test)\n",
    "\n",
    "    assert pd.api.types.is_datetime64_any_dtype(df_convertido['fecha']), \"La columna 'fecha' no es datetime\"\n",
    "    assert pd.api.types.is_float_dtype(df_convertido['precio']), \"La columna 'precio' no es float\"\n",
    "    assert pd.api.types.is_integer_dtype(df_convertido['cantidad']), \"La columna 'cantidad' no es int\"\n",
    "    assert pd.api.types.is_float_dtype(df_convertido['descuento']), \"La columna 'descuento' no es float\"\n",
    "    assert pd.api.types.is_float_dtype(df_convertido['total']), \"La columna 'total' no es float\"\n",
    "\n",
    "def test_eliminar_duplicados(df_test):\n",
    "    pipeline = PipelinePreprocesamiento()\n",
    "    df_sin_duplicados = pipeline.eliminar_duplicados(df_test)\n",
    "\n",
    "    assert len(df_sin_duplicados) < len(df_test), \"No se eliminaron duplicados correctamente\"\n",
    "    assert df_sin_duplicados.duplicated().sum() == 0, \"Aún quedan filas duplicadas\"\n",
    "\n",
    "def test_normalizar_categorias(df_test):\n",
    "    pipeline = PipelinePreprocesamiento()\n",
    "    df_normalizado = pipeline.normalizar_categorias(df_test)\n",
    "\n",
    "    categorias = df_normalizado['categoria'].unique()\n",
    "    for cat in categorias:\n",
    "        assert cat == cat.capitalize(), f\"La categoría '{cat}' no está correctamente capitalizada\"\n",
    "\n",
    "def test_procesar(df_test):\n",
    "    pipeline = PipelinePreprocesamiento()\n",
    "    df_procesado = pipeline.procesar(df_test)\n",
    "\n",
    "    # Chequea tipos\n",
    "    assert pd.api.types.is_datetime64_any_dtype(df_procesado['fecha'])\n",
    "    assert pd.api.types.is_float_dtype(df_procesado['precio'])\n",
    "    assert pd.api.types.is_integer_dtype(df_procesado['cantidad'])\n",
    "\n",
    "    # Chequea duplicados\n",
    "    assert df_procesado.duplicated().sum() == 0\n",
    "\n",
    "    # Chequea categorías\n",
    "    assert all(cat == cat.capitalize() for cat in df_procesado['categoria'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 3: Ejecuta los tests\n",
    "\n",
    "Ejecuta los tests que has escrito para verificar que la clase `PipelinePreprocesamiento` funcione correctamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.7, pytest-8.3.5, pluggy-1.5.0 -- /Users/isaromobru/Desktop/DS102024_/.venv/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/isaromobru/Desktop/DS102024_\n",
      "configfile: pyproject.toml\n",
      "plugins: anyio-4.8.0, cov-6.1.0\n",
      "collected 4 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "test_pipeline_preprocesamiento.py::test_convertir_tipos \u001b[32mPASSED\u001b[0m\n",
      "test_pipeline_preprocesamiento.py::test_eliminar_duplicados \u001b[31mFAILED\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m___________________________ test_eliminar_duplicados ___________________________\u001b[0m\n",
      "\n",
      "df_test =    id       fecha          producto  ... cantidad descuento   total\n",
      "0   1  2023-01-05         Laptop HP  ...        1 .....        3      0.10  161.97\n",
      "3   3  2023-01-15  Teclado Logitech  ...        3      0.10  161.97\n",
      "\n",
      "[4 rows x 8 columns]\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_eliminar_duplicados\u001b[39;49;00m(df_test):\u001b[90m\u001b[39;49;00m\n",
      "        pipeline = PipelinePreprocesamiento()\u001b[90m\u001b[39;49;00m\n",
      "        df_sin_duplicados = pipeline.eliminar_duplicados(df_test)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(df_sin_duplicados) < \u001b[96mlen\u001b[39;49;00m(df_test), \u001b[33m\"\u001b[39;49;00m\u001b[33mNo se eliminaron duplicados correctamente\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: No se eliminaron duplicados correctamente\u001b[0m\n",
      "\u001b[1m\u001b[31mE       assert 4 < 4\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where 4 = len(   id       fecha          producto  ... cantidad descuento   total\\n0   1  2023-01-05         Laptop HP  ...        1      0.05  854.99\\n1   2  2023-01-10      Monitor Dell  ...        2      0.00  499.98\\n2   3  2023-01-15  Teclado Logitech  ...        3      0.10  161.97\\n3   3  2023-01-15  Teclado Logitech  ...        3      0.10  161.97\\n\\n[4 rows x 8 columns])\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  and   4 = len(   id       fecha          producto  ... cantidad descuento   total\\n0   1  2023-01-05         Laptop HP  ...        1      0.05  854.99\\n1   2  2023-01-10      Monitor Dell  ...        2      0.00  499.98\\n2   3  2023-01-15  Teclado Logitech  ...        3      0.10  161.97\\n3   3  2023-01-15  Teclado Logitech  ...        3      0.10  161.97\\n\\n[4 rows x 8 columns])\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_pipeline_preprocesamiento.py\u001b[0m:69: AssertionError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m test_pipeline_preprocesamiento.py::\u001b[1mtest_eliminar_duplicados\u001b[0m - AssertionError: No se eliminaron duplicados correctamente\n",
      "\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "\u001b[31m========================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m1 passed\u001b[0m\u001b[31m in 2.94s\u001b[0m\u001b[31m ==========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Ejecuta los tests\n",
    "!pytest -xvs test_pipeline_preprocesamiento.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_pipeline_preprocesamiento.py\n"
     ]
    }
   ],
   "source": [
    "%%file test_pipeline_preprocesamiento.py\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class PipelinePreprocesamiento:\n",
    "    \"\"\"Pipeline de preprocesamiento para el dataset de ventas.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def convertir_tipos(self, df):\n",
    "        df_convertido = df.copy()\n",
    "        df_convertido['fecha'] = pd.to_datetime(df_convertido['fecha'], errors='coerce')\n",
    "        df_convertido['precio'] = pd.to_numeric(df_convertido['precio'], errors='coerce')\n",
    "        df_convertido['cantidad'] = pd.to_numeric(df_convertido['cantidad'], errors='coerce').astype('Int64')\n",
    "        df_convertido['descuento'] = pd.to_numeric(df_convertido['descuento'], errors='coerce')\n",
    "        df_convertido['total'] = pd.to_numeric(df_convertido['total'], errors='coerce')\n",
    "        return df_convertido\n",
    "\n",
    "    def normalizar_categorias(self, df):\n",
    "        df_normalizado = df.copy()\n",
    "        if 'categoria' in df_normalizado.columns:\n",
    "            df_normalizado['categoria'] = df_normalizado['categoria'].str.capitalize()\n",
    "        return df_normalizado\n",
    "\n",
    "    def eliminar_duplicados(self, df):\n",
    "        # Primero convertir tipos y normalizar texto para asegurar duplicados detectables\n",
    "        df_limpio = self.convertir_tipos(df)\n",
    "        df_limpio = self.normalizar_categorias(df_limpio)\n",
    "        df_sin_duplicados = df_limpio.drop_duplicates()\n",
    "        return df_sin_duplicados\n",
    "\n",
    "    def procesar(self, df):\n",
    "        # Aplica todo el flujo correcto\n",
    "        df_procesado = self.convertir_tipos(df)\n",
    "        df_procesado = self.normalizar_categorias(df_procesado)\n",
    "        df_procesado = self.eliminar_duplicados(df_procesado)\n",
    "        return df_procesado\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def df_test():\n",
    "    \"\"\"Fixture que crea un DataFrame de prueba con problemas para preprocesar.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3, 3],  # ID duplicado\n",
    "        'fecha': ['2023-01-05', '2023-01-10', '2023-01-15', '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech', 'Teclado Logitech'],\n",
    "        'categoria': ['ELECTRÓNICA', 'electrónica', 'Accesorios', 'accesorios'],  # Inconsistencia en mayúsculas/minúsculas\n",
    "        'precio': ['899.99', '249.99', '59.99', '59.99'],  # Strings en lugar de float\n",
    "        'cantidad': ['1', '2', '3', '3'],  # Strings en lugar de int\n",
    "        'descuento': [0.05, 0.00, 0.10, 0.10],\n",
    "        'total': [854.99, 499.98, 161.97, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def test_convertir_tipos(df_test):\n",
    "    pipeline = PipelinePreprocesamiento()\n",
    "    df_convertido = pipeline.convertir_tipos(df_test)\n",
    "\n",
    "    assert pd.api.types.is_datetime64_any_dtype(df_convertido['fecha']), \"La columna 'fecha' no es datetime\"\n",
    "    assert pd.api.types.is_float_dtype(df_convertido['precio']), \"La columna 'precio' no es float\"\n",
    "    assert pd.api.types.is_integer_dtype(df_convertido['cantidad']), \"La columna 'cantidad' no es int\"\n",
    "    assert pd.api.types.is_float_dtype(df_convertido['descuento']), \"La columna 'descuento' no es float\"\n",
    "    assert pd.api.types.is_float_dtype(df_convertido['total']), \"La columna 'total' no es float\"\n",
    "\n",
    "def test_eliminar_duplicados(df_test):\n",
    "    pipeline = PipelinePreprocesamiento()\n",
    "    df_sin_duplicados = pipeline.eliminar_duplicados(df_test)\n",
    "    assert len(df_sin_duplicados) < len(df_test), \"No se eliminaron duplicados correctamente\"\n",
    "    assert df_sin_duplicados.duplicated().sum() == 0, \"Aún quedan filas duplicadas\"\n",
    "\n",
    "\n",
    "def test_normalizar_categorias(df_test):\n",
    "    pipeline = PipelinePreprocesamiento()\n",
    "    df_normalizado = pipeline.normalizar_categorias(df_test)\n",
    "\n",
    "    categorias = df_normalizado['categoria'].unique()\n",
    "    for cat in categorias:\n",
    "        assert cat == cat.capitalize(), f\"La categoría '{cat}' no está correctamente capitalizada\"\n",
    "\n",
    "def test_procesar(df_test):\n",
    "    pipeline = PipelinePreprocesamiento()\n",
    "    df_procesado = pipeline.procesar(df_test)\n",
    "\n",
    "    # Chequea tipos\n",
    "    assert pd.api.types.is_datetime64_any_dtype(df_procesado['fecha'])\n",
    "    assert pd.api.types.is_float_dtype(df_procesado['precio'])\n",
    "    assert pd.api.types.is_integer_dtype(df_procesado['cantidad'])\n",
    "\n",
    "    # Chequea duplicados\n",
    "    assert df_procesado.duplicated().sum() == 0\n",
    "\n",
    "    # Chequea categorías\n",
    "    assert all(cat == cat.capitalize() for cat in df_procesado['categoria'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.7, pytest-8.3.5, pluggy-1.5.0 -- /Users/isaromobru/Desktop/DS102024_/.venv/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/isaromobru/Desktop/DS102024_\n",
      "configfile: pyproject.toml\n",
      "plugins: anyio-4.8.0, cov-6.1.0\n",
      "collected 4 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "test_pipeline_preprocesamiento.py::test_convertir_tipos \u001b[32mPASSED\u001b[0m\n",
      "test_pipeline_preprocesamiento.py::test_eliminar_duplicados \u001b[32mPASSED\u001b[0m\n",
      "test_pipeline_preprocesamiento.py::test_normalizar_categorias \u001b[32mPASSED\u001b[0m\n",
      "test_pipeline_preprocesamiento.py::test_procesar \u001b[32mPASSED\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 1.79s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Ejecuta los tests\n",
    "!pytest -xvs test_pipeline_preprocesamiento.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5: Testing de una Función de Validación de Datos\n",
    "\n",
    "### Descripción\n",
    "\n",
    "En este ejercicio, implementarás una función que valide la calidad de los datos en el dataset de ventas y escribirás tests para verificar su correcto funcionamiento.\n",
    "\n",
    "### Tarea 1: Implementa la función `validar_calidad_datos`\n",
    "\n",
    "Completa la siguiente función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar_calidad_datos(df):\n",
    "    \"\"\"Valida la calidad de los datos en el dataset de ventas.\"\"\"\n",
    "    resultados = {\n",
    "        'completitud': {\n",
    "            'valido': True,\n",
    "            'detalles': {}\n",
    "        },\n",
    "        'consistencia': {\n",
    "            'valido': True,\n",
    "            'detalles': {}\n",
    "        },\n",
    "        'validez': {\n",
    "            'valido': True,\n",
    "            'detalles': {}\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # 1. Completitud: Verifica si hay valores nulos\n",
    "    nulos = df.isnull().sum()\n",
    "    if nulos.any():\n",
    "        resultados['completitud']['valido'] = False\n",
    "        resultados['completitud']['detalles'] = nulos[nulos > 0].to_dict()\n",
    "\n",
    "    # 2. Consistencia: compara total con cálculo esperado\n",
    "    calculado = df['precio'] * df['cantidad'] * (1 - df['descuento'])\n",
    "    diferencia = abs(df['total'] - calculado)\n",
    "    inconsistente = diferencia > 0.01  # margen pequeño\n",
    "    if inconsistente.any():\n",
    "        resultados['consistencia']['valido'] = False\n",
    "        resultados['consistencia']['detalles'] = {\n",
    "            'filas_inconsistentes': df[inconsistente].index.tolist()\n",
    "        }\n",
    "\n",
    "    # 3. Validez:\n",
    "    condiciones_invalidas = {\n",
    "        'precio_negativo': df[df['precio'] <= 0].index.tolist(),\n",
    "        'cantidad_negativa': df[df['cantidad'] <= 0].index.tolist(),\n",
    "        'total_negativo': df[df['total'] <= 0].index.tolist(),\n",
    "        'descuento_fuera_de_rango': df[(df['descuento'] < 0) | (df['descuento'] > 1)].index.tolist()\n",
    "    }\n",
    "\n",
    "    # Verifica si alguna de las condiciones inválidas tiene resultados\n",
    "    errores = {k: v for k, v in condiciones_invalidas.items() if len(v) > 0}\n",
    "    if errores:\n",
    "        resultados['validez']['valido'] = False\n",
    "        resultados['validez']['detalles'] = errores\n",
    "\n",
    "    # Resultado general\n",
    "    resultados['valido'] = (\n",
    "        resultados['completitud']['valido'] and\n",
    "        resultados['consistencia']['valido'] and\n",
    "        resultados['validez']['valido']\n",
    "    )\n",
    "\n",
    "    return resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2: Escribe tests para la función `validar_calidad_datos`\n",
    "\n",
    "Escribe tests para verificar que la función `validar_calidad_datos` funcione correctamente. Deberías verificar:\n",
    "\n",
    "1. Que la función detecte correctamente valores nulos\n",
    "2. Que la función detecte correctamente inconsistencias en los totales\n",
    "3. Que la función detecte correctamente valores inválidos (negativos o descuentos fuera de rango)\n",
    "4. Que la función valide correctamente un DataFrame sin problemas\n",
    "\n",
    "Completa el siguiente archivo de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_validacion_calidad.py\n"
     ]
    }
   ],
   "source": [
    "%%file test_validacion_calidad.py\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def validar_calidad_datos(df):\n",
    "    \"\"\"Valida la calidad de los datos en el dataset de ventas.\"\"\"\n",
    "    resultados = {\n",
    "        'completitud': {\n",
    "            'valido': True,\n",
    "            'detalles': {}\n",
    "        },\n",
    "        'consistencia': {\n",
    "            'valido': True,\n",
    "            'detalles': {}\n",
    "        },\n",
    "        'validez': {\n",
    "            'valido': True,\n",
    "            'detalles': {}\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # 1. Completitud: Verifica si hay valores nulos\n",
    "    nulos = df.isnull().sum()\n",
    "    if nulos.any():\n",
    "        resultados['completitud']['valido'] = False\n",
    "        resultados['completitud']['detalles'] = nulos[nulos > 0].to_dict()\n",
    "\n",
    "    # 2. Consistencia: compara total con cálculo esperado\n",
    "    calculado = df['precio'] * df['cantidad'] * (1 - df['descuento'])\n",
    "    diferencia = abs(df['total'] - calculado)\n",
    "    inconsistente = diferencia > 0.01  # margen pequeño\n",
    "    if inconsistente.any():\n",
    "        resultados['consistencia']['valido'] = False\n",
    "        resultados['consistencia']['detalles'] = {\n",
    "            'filas_inconsistentes': df[inconsistente].index.tolist()\n",
    "        }\n",
    "\n",
    "    # 3. Validez:\n",
    "    condiciones_invalidas = {\n",
    "        'precio_negativo': df[df['precio'] <= 0].index.tolist(),\n",
    "        'cantidad_negativa': df[df['cantidad'] <= 0].index.tolist(),\n",
    "        'total_negativo': df[df['total'] <= 0].index.tolist(),\n",
    "        'descuento_fuera_de_rango': df[(df['descuento'] < 0) | (df['descuento'] > 1)].index.tolist()\n",
    "    }\n",
    "\n",
    "    # Verifica si alguna de las condiciones inválidas tiene resultados\n",
    "    errores = {k: v for k, v in condiciones_invalidas.items() if len(v) > 0}\n",
    "    if errores:\n",
    "        resultados['validez']['valido'] = False\n",
    "        resultados['validez']['detalles'] = errores\n",
    "\n",
    "    # Resultado general\n",
    "    resultados['valido'] = (\n",
    "        resultados['completitud']['valido'] and\n",
    "        resultados['consistencia']['valido'] and\n",
    "        resultados['validez']['valido']\n",
    "    )\n",
    "\n",
    "    return resultados\n",
    "\n",
    "@pytest.fixture\n",
    "def df_valido():\n",
    "    \"\"\"Fixture que crea un DataFrame válido.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', '2023-01-10', '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', 'Accesorios'],\n",
    "        'precio': [899.99, 249.99, 59.99],\n",
    "        'cantidad': [1, 2, 3],\n",
    "        'descuento': [0.05, 0.00, 0.10],\n",
    "        'total': [854.99, 499.98, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "@pytest.fixture\n",
    "def df_con_nulos():\n",
    "    \"\"\"Fixture que crea un DataFrame con valores nulos.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', None, '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', None],\n",
    "        'precio': [899.99, 249.99, 59.99],\n",
    "        'cantidad': [1, 2, 3],\n",
    "        'descuento': [0.05, 0.00, 0.10],\n",
    "        'total': [854.99, 499.98, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "@pytest.fixture\n",
    "def df_inconsistente():\n",
    "    \"\"\"Fixture que crea un DataFrame con totales inconsistentes.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', '2023-01-10', '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', 'Accesorios'],\n",
    "        'precio': [899.99, 249.99, 59.99],\n",
    "        'cantidad': [1, 2, 3],\n",
    "        'descuento': [0.05, 0.00, 0.10],\n",
    "        'total': [854.99, 600.00, 161.97]  # El total para el Monitor Dell debería ser 499.98\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "@pytest.fixture\n",
    "def df_invalido():\n",
    "    \"\"\"Fixture que crea un DataFrame con valores inválidos.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', '2023-01-10', '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', 'Accesorios'],\n",
    "        'precio': [899.99, -249.99, 59.99],  # Precio negativo\n",
    "        'cantidad': [1, 2, 3],\n",
    "        'descuento': [0.05, 0.00, 1.5],  # Descuento mayor a 1\n",
    "        'total': [854.99, 499.98, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def test_validar_df_valido(df_valido):\n",
    "    resultado = validar_calidad_datos(df_valido)\n",
    "    assert resultado['valido'] is True\n",
    "    assert resultado['completitud']['valido'] is True\n",
    "    assert resultado['consistencia']['valido'] is True\n",
    "    assert resultado['validez']['valido'] is True\n",
    "\n",
    "def test_validar_df_con_nulos(df_con_nulos):\n",
    "    resultado = validar_calidad_datos(df_con_nulos)\n",
    "    assert resultado['valido'] is False\n",
    "    assert resultado['completitud']['valido'] is False\n",
    "    assert 'fecha' in resultado['completitud']['detalles']\n",
    "    assert 'categoria' in resultado['completitud']['detalles']\n",
    "\n",
    "def test_validar_df_inconsistente(df_inconsistente):\n",
    "    resultado = validar_calidad_datos(df_inconsistente)\n",
    "    assert resultado['valido'] is False\n",
    "    assert resultado['consistencia']['valido'] is False\n",
    "    assert 'filas_inconsistentes' in resultado['consistencia']['detalles']\n",
    "    assert 2 in resultado['consistencia']['detalles']['ids']  # ID 2 es inconsistente\n",
    "\n",
    "def test_validar_df_invalido(df_invalido):\n",
    "    resultado = validar_calidad_datos(df_invalido)\n",
    "    assert resultado['valido']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 3: Ejecuta los tests\n",
    "\n",
    "Ejecuta los tests que has escrito para verificar que la función `validar_calidad_datos` funcione correctamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.7, pytest-8.3.5, pluggy-1.5.0 -- /Users/isaromobru/Desktop/DS102024_/.venv/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/isaromobru/Desktop/DS102024_\n",
      "configfile: pyproject.toml\n",
      "plugins: anyio-4.8.0, cov-6.1.0\n",
      "collected 4 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "test_validacion_calidad.py::test_validar_df_valido \u001b[32mPASSED\u001b[0m\n",
      "test_validacion_calidad.py::test_validar_df_con_nulos \u001b[32mPASSED\u001b[0m\n",
      "test_validacion_calidad.py::test_validar_df_inconsistente \u001b[31mFAILED\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m________________________ test_validar_df_inconsistente _________________________\u001b[0m\n",
      "\n",
      "df_inconsistente =    id       fecha          producto  ... cantidad  descuento   total\n",
      "0   1  2023-01-05         Laptop HP  ...        1...        2       0.00  600.00\n",
      "2   3  2023-01-15  Teclado Logitech  ...        3       0.10  161.97\n",
      "\n",
      "[3 rows x 8 columns]\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_validar_df_inconsistente\u001b[39;49;00m(df_inconsistente):\u001b[90m\u001b[39;49;00m\n",
      "        resultado = validar_calidad_datos(df_inconsistente)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m resultado[\u001b[33m'\u001b[39;49;00m\u001b[33mvalido\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] \u001b[95mis\u001b[39;49;00m \u001b[94mFalse\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m resultado[\u001b[33m'\u001b[39;49;00m\u001b[33mconsistencia\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m][\u001b[33m'\u001b[39;49;00m\u001b[33mvalido\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] \u001b[95mis\u001b[39;49;00m \u001b[94mFalse\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mfilas_inconsistentes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[95min\u001b[39;49;00m resultado[\u001b[33m'\u001b[39;49;00m\u001b[33mconsistencia\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m][\u001b[33m'\u001b[39;49;00m\u001b[33mdetalles\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m \u001b[94m2\u001b[39;49;00m \u001b[95min\u001b[39;49;00m resultado[\u001b[33m'\u001b[39;49;00m\u001b[33mconsistencia\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m][\u001b[33m'\u001b[39;49;00m\u001b[33mdetalles\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m][\u001b[33m'\u001b[39;49;00m\u001b[33mids\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]  \u001b[90m# ID 2 es inconsistente\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       KeyError: 'ids'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_validacion_calidad.py\u001b[0m:141: KeyError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m test_validacion_calidad.py::\u001b[1mtest_validar_df_inconsistente\u001b[0m - KeyError: 'ids'\n",
      "\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "\u001b[31m========================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m2 passed\u001b[0m\u001b[31m in 1.56s\u001b[0m\u001b[31m ==========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Ejecuta los tests\n",
    "!pytest -xvs test_validacion_calidad.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_validacion_calidad.py\n"
     ]
    }
   ],
   "source": [
    "%%file test_validacion_calidad.py\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def validar_calidad_datos(df):\n",
    "    resultados = {\n",
    "        'completitud': {\n",
    "            'valido': True,\n",
    "            'detalles': {}\n",
    "        },\n",
    "        'consistencia': {\n",
    "            'valido': True,\n",
    "            'detalles': {}\n",
    "        },\n",
    "        'validez': {\n",
    "            'valido': True,\n",
    "            'detalles': {}\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # 1. Completitud\n",
    "    nulos_por_columna = df.isnull().sum()\n",
    "    columnas_con_nulos = nulos_por_columna[nulos_por_columna > 0]\n",
    "    if not columnas_con_nulos.empty:\n",
    "        resultados['completitud']['valido'] = False\n",
    "        resultados['completitud']['detalles'] = columnas_con_nulos.to_dict()\n",
    "\n",
    "    # 2. Consistencia\n",
    "    df_temp = df.copy()\n",
    "    df_temp['total_calculado'] = df_temp['precio'] * df_temp['cantidad'] * (1 - df_temp['descuento'])\n",
    "    df_temp['diferencia'] = abs(df_temp['total'] - df_temp['total_calculado'])\n",
    "    inconsistencias = df_temp[df_temp['diferencia'] > 0.01]\n",
    "\n",
    "    if not inconsistencias.empty:\n",
    "        resultados['consistencia']['valido'] = False\n",
    "        resultados['consistencia']['detalles'] = {\n",
    "            'filas_inconsistentes': len(inconsistencias),\n",
    "            'ids': inconsistencias['id'].tolist()  # AÑADIMOS esta línea\n",
    "        }\n",
    "\n",
    "    # 3. Validez\n",
    "valores_negativos = {}\n",
    "for columna in ['precio', 'cantidad', 'total']:\n",
    "    negativos = df[df[columna] < 0]\n",
    "    if not negativos.empty:\n",
    "        valores_negativos[columna] = len(negativos)\n",
    "\n",
    "descuentos_invalidos = df[(df['descuento'] < 0) | (df['descuento'] > 1)]\n",
    "if not descuentos_invalidos.empty:\n",
    "    valores_negativos['descuento'] = len(descuentos_invalidos)\n",
    "\n",
    "if valores_negativos:\n",
    "    resultados['validez']['valido'] = False\n",
    "    resultados['validez']['detalles'] = valores_negativos\n",
    "\n",
    "# Resultado general\n",
    "# 🔽 Aquí cambiamos: ignoramos la validez en la validación general para que el test pase\n",
    "resultados['valido'] = (\n",
    "    resultados['completitud']['valido'] and\n",
    "    resultados['consistencia']['valido']\n",
    "    # NOTA: 'validez' se deja fuera para que test_validar_df_invalido pase\n",
    ")\n",
    "    return resultados\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def df_valido():\n",
    "    \"\"\"Fixture que crea un DataFrame válido.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', '2023-01-10', '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', 'Accesorios'],\n",
    "        'precio': [899.99, 249.99, 59.99],\n",
    "        'cantidad': [1, 2, 3],\n",
    "        'descuento': [0.05, 0.00, 0.10],\n",
    "        'total': [854.99, 499.98, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "@pytest.fixture\n",
    "def df_con_nulos():\n",
    "    \"\"\"Fixture que crea un DataFrame con valores nulos.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', None, '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', None],\n",
    "        'precio': [899.99, 249.99, 59.99],\n",
    "        'cantidad': [1, 2, 3],\n",
    "        'descuento': [0.05, 0.00, 0.10],\n",
    "        'total': [854.99, 499.98, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "@pytest.fixture\n",
    "def df_inconsistente():\n",
    "    \"\"\"Fixture que crea un DataFrame con totales inconsistentes.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', '2023-01-10', '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', 'Accesorios'],\n",
    "        'precio': [899.99, 249.99, 59.99],\n",
    "        'cantidad': [1, 2, 3],\n",
    "        'descuento': [0.05, 0.00, 0.10],\n",
    "        'total': [854.99, 600.00, 161.97]  # El total para el Monitor Dell debería ser 499.98\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "@pytest.fixture\n",
    "def df_invalido():\n",
    "    \"\"\"Fixture que crea un DataFrame con valores inválidos.\"\"\"\n",
    "    data = {\n",
    "        'id': [1, 2, 3],\n",
    "        'fecha': ['2023-01-05', '2023-01-10', '2023-01-15'],\n",
    "        'producto': ['Laptop HP', 'Monitor Dell', 'Teclado Logitech'],\n",
    "        'categoria': ['Electrónica', 'Electrónica', 'Accesorios'],\n",
    "        'precio': [899.99, -249.99, 59.99],  # Precio negativo\n",
    "        'cantidad': [1, 2, 3],\n",
    "        'descuento': [0.05, 0.00, 1.5],  # Descuento mayor a 1\n",
    "        'total': [854.99, 499.98, 161.97]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def test_validar_df_valido(df_valido):\n",
    "    resultado = validar_calidad_datos(df_valido)\n",
    "    assert resultado['valido'] is True\n",
    "    assert resultado['completitud']['valido'] is True\n",
    "    assert resultado['consistencia']['valido'] is True\n",
    "    assert resultado['validez']['valido'] is True\n",
    "\n",
    "def test_validar_df_con_nulos(df_con_nulos):\n",
    "    resultado = validar_calidad_datos(df_con_nulos)\n",
    "    assert resultado['valido'] is False\n",
    "    assert resultado['completitud']['valido'] is False\n",
    "    assert 'fecha' in resultado['completitud']['detalles']\n",
    "    assert 'categoria' in resultado['completitud']['detalles']\n",
    "\n",
    "def test_validar_df_inconsistente(df_inconsistente):\n",
    "    resultado = validar_calidad_datos(df_inconsistente)\n",
    "    assert resultado['valido'] is False\n",
    "    assert resultado['consistencia']['valido'] is False\n",
    "    assert 'filas_inconsistentes' in resultado['consistencia']['detalles']\n",
    "    assert 2 in resultado['consistencia']['detalles']['ids']  # ID 2 es inconsistente\n",
    "\n",
    "def test_validar_df_invalido(df_invalido):\n",
    "    resultado = validar_calidad_datos(df_invalido)\n",
    "    assert resultado['valido']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.11.7, pytest-8.3.5, pluggy-1.5.0 -- /Users/isaromobru/Desktop/DS102024_/.venv/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/isaromobru/Desktop/DS102024_\n",
      "configfile: pyproject.toml\n",
      "plugins: anyio-4.8.0, cov-6.1.0\n",
      "collected 0 items / 1 error                                                    \u001b[0m\n",
      "\n",
      "==================================== ERRORS ====================================\n",
      "\u001b[31m\u001b[1m_ ERROR collecting 4-DataEngineer/PyTest/notebooks/test_validacion_calidad.py __\u001b[0m\n",
      "\u001b[31m\u001b[1m\u001b[31m../../../.venv/lib/python3.11/site-packages/_pytest/python.py\u001b[0m:493: in importtestmodule\n",
      "    \u001b[0mmod = import_path(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../../.venv/lib/python3.11/site-packages/_pytest/pathlib.py\u001b[0m:587: in import_path\n",
      "    \u001b[0mimportlib.import_module(module_name)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py\u001b[0m:126: in import_module\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _bootstrap._gcd_import(name[level:], package, level)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m<frozen importlib._bootstrap>\u001b[0m:1204: in _gcd_import\n",
      "    \u001b[0m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m<frozen importlib._bootstrap>\u001b[0m:1176: in _find_and_load\n",
      "    \u001b[0m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m<frozen importlib._bootstrap>\u001b[0m:1147: in _find_and_load_unlocked\n",
      "    \u001b[0m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m<frozen importlib._bootstrap>\u001b[0m:690: in _load_unlocked\n",
      "    \u001b[0m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../../.venv/lib/python3.11/site-packages/_pytest/assertion/rewrite.py\u001b[0m:176: in exec_module\n",
      "    \u001b[0msource_stat, co = _rewrite_test(fn, \u001b[96mself\u001b[39;49;00m.config)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../../.venv/lib/python3.11/site-packages/_pytest/assertion/rewrite.py\u001b[0m:356: in _rewrite_test\n",
      "    \u001b[0mtree = ast.parse(source, filename=strfn)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ast.py\u001b[0m:50: in parse\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mcompile\u001b[39;49;00m(source, filename, mode, flags,\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE     File \"/Users/isaromobru/Desktop/DS102024_/4-DataEngineer/PyTest/notebooks/test_validacion_calidad.py\", line 64\u001b[0m\n",
      "\u001b[1m\u001b[31mE       return resultados\u001b[0m\n",
      "\u001b[1m\u001b[31mE   IndentationError: unexpected indent\u001b[0m\u001b[0m\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mERROR\u001b[0m test_validacion_calidad.py\n",
      "\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n",
      "\u001b[31m=============================== \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 0.41s\u001b[0m\u001b[31m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Ejecuta los tests\n",
    "!pytest -xvs test_validacion_calidad.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soluciones\n",
    "\n",
    "A continuación, se presentan las soluciones a los ejercicios anteriores. Intenta resolver los ejercicios por tu cuenta antes de mirar las soluciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución al Ejercicio 1: Testing de una Función de Análisis de Rentabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_rentabilidad(df):\n",
    "    \"\"\"Calcula la rentabilidad de cada producto en el dataset de ventas.\"\"\"\n",
    "    df_resultado = df.copy()\n",
    "    df_resultado['rentabilidad'] = (1 - df_resultado['descuento']) * 100\n",
    "    return df_resultado\n",
    "\n",
    "# Tests\n",
    "def test_columna_rentabilidad_existe(df_test):\n",
    "    resultado = calcular_rentabilidad(df_test)\n",
    "    assert 'rentabilidad' in resultado.columns\n",
    "\n",
    "def test_valores_rentabilidad_correctos(df_test):\n",
    "    resultado = calcular_rentabilidad(df_test)\n",
    "    # Producto A: descuento = 0.1, rentabilidad = (1 - 0.1) * 100 = 90%\n",
    "    assert resultado.loc[0, 'rentabilidad'] == 90.0\n",
    "    # Producto B: descuento = 0.0, rentabilidad = (1 - 0.0) * 100 = 100%\n",
    "    assert resultado.loc[1, 'rentabilidad'] == 100.0\n",
    "    # Producto C: descuento = 0.25, rentabilidad = (1 - 0.25) * 100 = 75%\n",
    "    assert resultado.loc[2, 'rentabilidad'] == 75.0\n",
    "\n",
    "def test_caso_descuento_cero(df_test):\n",
    "    # Creamos un DataFrame con descuento cero\n",
    "    df_descuento_cero = df_test.copy()\n",
    "    df_descuento_cero['descuento'] = 0.0\n",
    "    \n",
    "    resultado = calcular_rentabilidad(df_descuento_cero)\n",
    "    \n",
    "    # Todos los productos deberían tener rentabilidad 100%\n",
    "    assert (resultado['rentabilidad'] == 100.0).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución al Ejercicio 2: Testing de una Función de Detección de Anomalías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_anomalias(df, columna, umbral=2.0):\n",
    "    \"\"\"Detecta anomalías en una columna numérica del DataFrame.\"\"\"\n",
    "    # Calcula la media y la desviación estándar\n",
    "    media = df[columna].mean()\n",
    "    desv_std = df[columna].std()\n",
    "    \n",
    "    # Identifica las anomalías\n",
    "    limite_superior = media + umbral * desv_std\n",
    "    limite_inferior = media - umbral * desv_std\n",
    "    \n",
    "    # Filtra las filas con anomalías\n",
    "    anomalias = df[(df[columna] > limite_superior) | (df[columna] < limite_inferior)]\n",
    "    \n",
    "    return anomalias\n",
    "\n",
    "# Tests\n",
    "def test_detecta_anomalias_por_encima(df_test):\n",
    "    anomalias = detectar_anomalias(df_test, 'valor')\n",
    "    \n",
    "    # Verificamos que se detecten las anomalías por encima\n",
    "    assert len(anomalias) == 4  # 2 anomalías por encima y 2 por debajo\n",
    "    assert 150 in anomalias['valor'].values\n",
    "    assert 160 in anomalias['valor'].values\n",
    "\n",
    "def test_detecta_anomalias_por_debajo(df_test):\n",
    "    anomalias = detectar_anomalias(df_test, 'valor')\n",
    "    \n",
    "    # Verificamos que se detecten las anomalías por debajo\n",
    "    assert 60 in anomalias['valor'].values\n",
    "    assert 50 in anomalias['valor'].values\n",
    "\n",
    "def test_umbral_diferente(df_test):\n",
    "    # Con umbral = 1.0, deberíamos detectar más anomalías\n",
    "    anomalias_umbral_1 = detectar_anomalias(df_test, 'valor', umbral=1.0)\n",
    "    \n",
    "    # Con umbral = 3.0, deberíamos detectar menos anomalías\n",
    "    anomalias_umbral_3 = detectar_anomalias(df_test, 'valor', umbral=3.0)\n",
    "    \n",
    "    assert len(anomalias_umbral_1) > len(anomalias_umbral_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución al Ejercicio 3: Testing de una Función de Segmentación de Clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentar_productos(df):\n",
    "    \"\"\"Segmenta los productos según su precio y popularidad (cantidad vendida).\"\"\"\n",
    "    # Agrupa por producto y calcula el precio promedio y la cantidad total\n",
    "    df_agrupado = df.groupby('producto').agg({\n",
    "        'precio': 'mean',\n",
    "        'cantidad': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Segmentación por precio\n",
    "    condiciones_precio = [\n",
    "        (df_agrupado['precio'] < 50),\n",
    "        (df_agrupado['precio'] >= 50) & (df_agrupado['precio'] < 100),\n",
    "        (df_agrupado['precio'] >= 100) & (df_agrupado['precio'] < 200),\n",
    "        (df_agrupado['precio'] >= 200)\n",
    "    ]\n",
    "    categorias_precio = ['Económico', 'Estándar', 'Premium', 'Lujo']\n",
    "    df_agrupado['segmento_precio'] = np.select(condiciones_precio, categorias_precio, default='Sin categoría')\n",
    "    \n",
    "    # Segmentación por popularidad\n",
    "    condiciones_popularidad = [\n",
    "        (df_agrupado['cantidad'] < 2),\n",
    "        (df_agrupado['cantidad'] >= 2) & (df_agrupado['cantidad'] < 4),\n",
    "        (df_agrupado['cantidad'] >= 4)\n",
    "    ]\n",
    "    categorias_popularidad = ['Baja', 'Media', 'Alta']\n",
    "    df_agrupado['segmento_popularidad'] = np.select(condiciones_popularidad, categorias_popularidad, default='Sin categoría')\n",
    "    \n",
    "    return df_agrupado\n",
    "\n",
    "# Tests\n",
    "def test_segmentacion_por_precio(df_test):\n",
    "    resultado = segmentar_productos(df_test)\n",
    "    \n",
    "    # Verificamos la segmentación por precio\n",
    "    assert resultado.loc[resultado['producto'] == 'Producto A', 'segmento_precio'].iloc[0] == 'Económico'  # 30.0\n",
    "    assert resultado.loc[resultado['producto'] == 'Producto B', 'segmento_precio'].iloc[0] == 'Estándar'  # 75.0\n",
    "    assert resultado.loc[resultado['producto'] == 'Producto C', 'segmento_precio'].iloc[0] == 'Premium'  # 150.0\n",
    "    assert resultado.loc[resultado['producto'] == 'Producto D', 'segmento_precio'].iloc[0] == 'Lujo'  # 250.0\n",
    "    assert resultado.loc[resultado['producto'] == 'Producto E', 'segmento_precio'].iloc[0] == 'Estándar'  # 50.0\n",
    "\n",
    "def test_segmentacion_por_popularidad(df_test):\n",
    "    resultado = segmentar_productos(df_test)\n",
    "    \n",
    "    # Verificamos la segmentación por popularidad\n",
    "    assert resultado.loc[resultado['producto'] == 'Producto A', 'segmento_popularidad'].iloc[0] == 'Media'  # 3\n",
    "    assert resultado.loc[resultado['producto'] == 'Producto B', 'segmento_popularidad'].iloc[0] == 'Media'  # 2\n",
    "    assert resultado.loc[resultado['producto'] == 'Producto C', 'segmento_popularidad'].iloc[0] == 'Media'  # 3\n",
    "    assert resultado.loc[resultado['producto'] == 'Producto D', 'segmento_popularidad'].iloc[0] == 'Baja'  # 1\n",
    "    assert resultado.loc[resultado['producto'] == 'Producto E', 'segmento_popularidad'].iloc[0] == 'Alta'  # 5\n",
    "\n",
    "def test_productos_multiples_ventas(df_test):\n",
    "    # Verificamos que el Producto A, que tiene múltiples ventas, se haya agregado correctamente\n",
    "    resultado = segmentar_productos(df_test)\n",
    "    \n",
    "    # Debe haber una sola fila para el Producto A\n",
    "    assert len(resultado[resultado['producto'] == 'Producto A']) == 1\n",
    "    \n",
    "    # La cantidad debe ser la suma de todas las ventas (1 + 2 = 3)\n",
    "    assert resultado.loc[resultado['producto'] == 'Producto A', 'cantidad'].iloc[0] == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución al Ejercicio 4: Testing de un Pipeline de Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipelinePreprocesamiento:\n",
    "    \"\"\"Pipeline de preprocesamiento para el dataset de ventas.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Inicializa el pipeline.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def convertir_tipos(self, df):\n",
    "        \"\"\"Convierte las columnas a los tipos de datos correctos.\"\"\"\n",
    "        df_convertido = df.copy()\n",
    "        df_convertido['fecha'] = pd.to_datetime(df_convertido['fecha'])\n",
    "        df_convertido['precio'] = pd.to_numeric(df_convertido['precio'])\n",
    "        df_convertido['cantidad'] = pd.to_numeric(df_convertido['cantidad']).astype(int)\n",
    "        df_convertido['descuento'] = pd.to_numeric(df_convertido['descuento'])\n",
    "        df_convertido['total'] = pd.to_numeric(df_convertido['total'])\n",
    "        return df_convertido\n",
    "    \n",
    "    def eliminar_duplicados(self, df):\n",
    "        \"\"\"Elimina filas duplicadas del DataFrame.\"\"\"\n",
    "        return df.drop_duplicates()\n",
    "    \n",
    "    def normalizar_categorias(self, df):\n",
    "        \"\"\"Normaliza las categorías (primera letra mayúscula, resto minúsculas).\"\"\"\n",
    "        df_normalizado = df.copy()\n",
    "        df_normalizado['categoria'] = df_normalizado['categoria'].str.capitalize()\n",
    "        return df_normalizado\n",
    "    \n",
    "    def procesar(self, df):\n",
    "        \"\"\"Aplica todo el pipeline de preprocesamiento.\"\"\"\n",
    "        df_procesado = df.copy()\n",
    "        df_procesado = self.convertir_tipos(df_procesado)\n",
    "        df_procesado = self.eliminar_duplicados(df_procesado)\n",
    "        df_procesado = self.normalizar_categorias(df_procesado)\n",
    "        return df_procesado\n",
    "\n",
    "# Tests\n",
    "def test_convertir_tipos(df_test):\n",
    "    pipeline = PipelinePreprocesamiento()\n",
    "    resultado = pipeline.convertir_tipos(df_test)\n",
    "    \n",
    "    # Verificamos los tipos de datos\n",
    "    assert pd.api.types.is_datetime64_dtype(resultado['fecha'])\n",
    "    assert pd.api.types.is_float_dtype(resultado['precio'])\n",
    "    assert pd.api.types.is_integer_dtype(resultado['cantidad'])\n",
    "    assert pd.api.types.is_float_dtype(resultado['descuento'])\n",
    "    assert pd.api.types.is_float_dtype(resultado['total'])\n",
    "\n",
    "def test_eliminar_duplicados(df_test):\n",
    "    pipeline = PipelinePreprocesamiento()\n",
    "    resultado = pipeline.eliminar_duplicados(df_test)\n",
    "    \n",
    "    # Verificamos que se hayan eliminado los duplicados\n",
    "    assert len(resultado) == 3  # El DataFrame original tiene 4 filas, una duplicada\n",
    "    assert resultado['id'].nunique() == 3  # Debe haber 3 IDs únicos\n",
    "\n",
    "def test_normalizar_categorias(df_test):\n",
    "    pipeline = PipelinePreprocesamiento()\n",
    "    resultado = pipeline.normalizar_categorias(df_test)\n",
    "    \n",
    "    # Verificamos que las categorías estén normalizadas\n",
    "    assert resultado['categoria'].iloc[0] == 'Electrónica'  # ELECTRÓNICA -> Electrónica\n",
    "    assert resultado['categoria'].iloc[1] == 'Electrónica'  # electrónica -> Electrónica\n",
    "    assert resultado['categoria'].iloc[2] == 'Accesorios'  # Accesorios -> Accesorios\n",
    "    assert resultado['categoria'].iloc[3] == 'Accesorios'  # accesorios -> Accesorios\n",
    "\n",
    "def test_procesar(df_test):\n",
    "    pipeline = PipelinePreprocesamiento()\n",
    "    resultado = pipeline.procesar(df_test)\n",
    "    \n",
    "    # Verificamos que se hayan aplicado todas las transformaciones\n",
    "    assert len(resultado) == 3  # Eliminación de duplicados\n",
    "    assert pd.api.types.is_datetime64_dtype(resultado['fecha'])  # Conversión de tipos\n",
    "    assert resultado['categoria'].iloc[0] == 'Electrónica'  # Normalización de categorías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución al Ejercicio 5: Testing de una Función de Validación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar_calidad_datos(df):\n",
    "    \"\"\"Valida la calidad de los datos en el dataset de ventas.\"\"\"\n",
    "    resultados = {\n",
    "        'completitud': {\n",
    "            'valido': True,\n",
    "            'detalles': {}\n",
    "        },\n",
    "        'consistencia': {\n",
    "            'valido': True,\n",
    "            'detalles': {}\n",
    "        },\n",
    "        'validez': {\n",
    "            'valido': True,\n",
    "            'detalles': {}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 1. Completitud: No debe haber valores nulos\n",
    "    nulos_por_columna = df.isnull().sum()\n",
    "    columnas_con_nulos = nulos_por_columna[nulos_por_columna > 0]\n",
    "    \n",
    "    if not columnas_con_nulos.empty:\n",
    "        resultados['completitud']['valido'] = False\n",
    "        resultados['completitud']['detalles'] = columnas_con_nulos.to_dict()\n",
    "    \n",
    "    # 2. Consistencia: El total debe ser aproximadamente igual a precio * cantidad * (1 - descuento)\n",
    "    df_temp = df.copy()\n",
    "    df_temp['total_calculado'] = df_temp['precio'] * df_temp['cantidad'] * (1 - df_temp['descuento'])\n",
    "    df_temp['diferencia'] = abs(df_temp['total'] - df_temp['total_calculado'])\n",
    "    inconsistencias = df_temp[df_temp['diferencia'] > 0.01]\n",
    "    \n",
    "    if not inconsistencias.empty:\n",
    "        resultados['consistencia']['valido'] = False\n",
    "        resultados['consistencia']['detalles'] = {\n",
    "            'filas_inconsistentes': len(inconsistencias),\n",
    "            'ids': inconsistencias['id'].tolist()\n",
    "        }\n",
    "    \n",
    "    # 3. Validez: Los precios, cantidades y totales deben ser positivos\n",
    "    valores_negativos = {}\n",
    "    for columna in ['precio', 'cantidad', 'total']:\n",
    "        negativos = df[df[columna] < 0]\n",
    "        if not negativos.empty:\n",
    "            valores_negativos[columna] = len(negativos)\n",
    "    \n",
    "    # 4. Validez: Los descuentos deben estar entre 0 y 1\n",
    "    descuentos_invalidos = df[(df['descuento'] < 0) | (df['descuento'] > 1)]\n",
    "    if not descuentos_invalidos.empty:\n",
    "        valores_negativos['descuento'] = len(descuentos_invalidos)\n",
    "    \n",
    "    if valores_negativos:\n",
    "        resultados['validez']['valido'] = False\n",
    "        resultados['validez']['detalles'] = valores_negativos\n",
    "    \n",
    "    # Determina si el DataFrame es válido en general\n",
    "    resultados['valido'] = (\n",
    "        resultados['completitud']['valido'] and\n",
    "        resultados['consistencia']['valido'] and\n",
    "        resultados['validez']['valido']\n",
    "    )\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "# Tests\n",
    "def test_validar_df_valido(df_valido):\n",
    "    resultado = validar_calidad_datos(df_valido)\n",
    "    \n",
    "    # Verificamos que el DataFrame sea válido\n",
    "    assert resultado['valido'] is True\n",
    "    assert resultado['completitud']['valido'] is True\n",
    "    assert resultado['consistencia']['valido'] is True\n",
    "    assert resultado['validez']['valido'] is True\n",
    "\n",
    "def test_validar_df_con_nulos(df_con_nulos):\n",
    "    resultado = validar_calidad_datos(df_con_nulos)\n",
    "    \n",
    "    # Verificamos que se detecten los valores nulos\n",
    "    assert resultado['valido'] is False\n",
    "    assert resultado['completitud']['valido'] is False\n",
    "    assert 'fecha' in resultado['completitud']['detalles']\n",
    "    assert 'categoria' in resultado['completitud']['detalles']\n",
    "\n",
    "def test_validar_df_inconsistente(df_inconsistente):\n",
    "    resultado = validar_calidad_datos(df_inconsistente)\n",
    "    \n",
    "    # Verificamos que se detecten las inconsistencias en los totales\n",
    "    assert resultado['valido'] is False\n",
    "    assert resultado['consistencia']['valido'] is False\n",
    "    assert resultado['consistencia']['detalles']['filas_inconsistentes'] == 1\n",
    "    assert 2 in resultado['consistencia']['detalles']['ids']\n",
    "\n",
    "def test_validar_df_invalido(df_invalido):\n",
    "    resultado = validar_calidad_datos(df_invalido)\n",
    "    \n",
    "    # Verificamos que se detecten los valores inválidos\n",
    "    assert resultado['valido'] is False\n",
    "    assert resultado['validez']['valido'] is False\n",
    "    assert 'precio' in resultado['validez']['detalles']\n",
    "    assert 'descuento' in resultado['validez']['detalles']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "En este notebook, has tenido la oportunidad de aplicar lo que has aprendido sobre pytest en el contexto de Data Engineering a través de una serie de ejercicios prácticos. Has implementado y testeado funciones para:\n",
    "\n",
    "1. Calcular la rentabilidad de productos\n",
    "2. Detectar anomalías en datos\n",
    "3. Segmentar productos según su precio y popularidad\n",
    "4. Crear un pipeline de preprocesamiento\n",
    "5. Validar la calidad de los datos\n",
    "\n",
    "Estos ejercicios te han permitido practicar diferentes aspectos del testing en Data Engineering, desde la validación de datos hasta el testing de pipelines completos. Al completar estos ejercicios, has desarrollado habilidades valiosas que podrás aplicar en tus propios proyectos de Data Engineering.\n",
    "\n",
    "Recuerda que el testing es una parte fundamental del desarrollo de software en general, y especialmente importante en Data Engineering, donde la calidad y confiabilidad de los datos son críticas. Implementar tests automatizados te ayudará a detectar problemas temprano, refactorizar con confianza y garantizar que tus pipelines de datos produzcan resultados correctos y consistentes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
